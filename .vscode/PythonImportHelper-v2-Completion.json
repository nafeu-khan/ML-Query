[
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "stringify",
        "importPath": "flatted",
        "description": "flatted",
        "isExtraImport": true,
        "detail": "flatted",
        "documentation": {}
    },
    {
        "label": "parse",
        "importPath": "flatted",
        "description": "flatted",
        "isExtraImport": true,
        "detail": "flatted",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "peewee",
        "description": "peewee",
        "isExtraImport": true,
        "detail": "peewee",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "peewee",
        "description": "peewee",
        "isExtraImport": true,
        "detail": "peewee",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "peewee",
        "description": "peewee",
        "isExtraImport": true,
        "detail": "peewee",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "peewee",
        "description": "peewee",
        "isExtraImport": true,
        "detail": "peewee",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "peewee",
        "description": "peewee",
        "isExtraImport": true,
        "detail": "peewee",
        "documentation": {}
    },
    {
        "label": "datetime",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "datetime",
        "description": "datetime",
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "logging,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging.",
        "description": "logging.",
        "detail": "logging.",
        "documentation": {}
    },
    {
        "label": "matplotlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib",
        "description": "matplotlib",
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "pyplot",
        "importPath": "matplotlib",
        "description": "matplotlib",
        "isExtraImport": true,
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "pprint",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pprint",
        "description": "pprint",
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "base64",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "base64",
        "description": "base64",
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "io",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "io",
        "description": "io",
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "BytesIO",
        "importPath": "io",
        "description": "io",
        "isExtraImport": true,
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "dill",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "dill",
        "description": "dill",
        "detail": "dill",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "record",
        "importPath": "numpy",
        "description": "numpy",
        "isExtraImport": true,
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "Counter",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "LinearRegression",
        "importPath": "sklearn.linear_model",
        "description": "sklearn.linear_model",
        "isExtraImport": true,
        "detail": "sklearn.linear_model",
        "documentation": {}
    },
    {
        "label": "LinearRegression",
        "importPath": "sklearn.linear_model",
        "description": "sklearn.linear_model",
        "isExtraImport": true,
        "detail": "sklearn.linear_model",
        "documentation": {}
    },
    {
        "label": "LinearRegression",
        "importPath": "sklearn.linear_model",
        "description": "sklearn.linear_model",
        "isExtraImport": true,
        "detail": "sklearn.linear_model",
        "documentation": {}
    },
    {
        "label": "LogisticRegression",
        "importPath": "sklearn.linear_model",
        "description": "sklearn.linear_model",
        "isExtraImport": true,
        "detail": "sklearn.linear_model",
        "documentation": {}
    },
    {
        "label": "LinearRegression",
        "importPath": "sklearn.linear_model",
        "description": "sklearn.linear_model",
        "isExtraImport": true,
        "detail": "sklearn.linear_model",
        "documentation": {}
    },
    {
        "label": "LogisticRegression",
        "importPath": "sklearn.linear_model",
        "description": "sklearn.linear_model",
        "isExtraImport": true,
        "detail": "sklearn.linear_model",
        "documentation": {}
    },
    {
        "label": "median_absolute_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "median_absolute_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "r2_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "mean_squared_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "confusion_matrix",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "r2_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "mean_squared_error",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "Orient",
        "importPath": "altair",
        "description": "altair",
        "isExtraImport": true,
        "detail": "altair",
        "documentation": {}
    },
    {
        "label": "X2Datum",
        "importPath": "altair",
        "description": "altair",
        "isExtraImport": true,
        "detail": "altair",
        "documentation": {}
    },
    {
        "label": "X2Datum",
        "importPath": "altair",
        "description": "altair",
        "isExtraImport": true,
        "detail": "altair",
        "documentation": {}
    },
    {
        "label": "KMeans",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "KMeans",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "AgglomerativeClustering",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "DBSCAN",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "KMeans",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "AgglomerativeClustering",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "DBSCAN",
        "importPath": "sklearn.cluster",
        "description": "sklearn.cluster",
        "isExtraImport": true,
        "detail": "sklearn.cluster",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "sqlite3",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sqlite3",
        "description": "sqlite3",
        "detail": "sqlite3",
        "documentation": {}
    },
    {
        "label": "uuid",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "uuid",
        "description": "uuid",
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "category_encoders",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "category_encoders",
        "description": "category_encoders",
        "detail": "category_encoders",
        "documentation": {}
    },
    {
        "label": "pickle",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pickle",
        "description": "pickle",
        "detail": "pickle",
        "documentation": {}
    },
    {
        "label": "RandomForestRegressor",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "GradientBoostingRegressor",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "GradientBoostingClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestRegressor",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "GradientBoostingRegressor",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "GradientBoostingClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "SVR",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVR",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "KNeighborsRegressor",
        "importPath": "sklearn.neighbors",
        "description": "sklearn.neighbors",
        "isExtraImport": true,
        "detail": "sklearn.neighbors",
        "documentation": {}
    },
    {
        "label": "KNeighborsClassifier",
        "importPath": "sklearn.neighbors",
        "description": "sklearn.neighbors",
        "isExtraImport": true,
        "detail": "sklearn.neighbors",
        "documentation": {}
    },
    {
        "label": "KNeighborsRegressor",
        "importPath": "sklearn.neighbors",
        "description": "sklearn.neighbors",
        "isExtraImport": true,
        "detail": "sklearn.neighbors",
        "documentation": {}
    },
    {
        "label": "KNeighborsClassifier",
        "importPath": "sklearn.neighbors",
        "description": "sklearn.neighbors",
        "isExtraImport": true,
        "detail": "sklearn.neighbors",
        "documentation": {}
    },
    {
        "label": "seaborn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "seaborn",
        "description": "seaborn",
        "detail": "seaborn",
        "documentation": {}
    },
    {
        "label": "plot",
        "importPath": "sympy",
        "description": "sympy",
        "isExtraImport": true,
        "detail": "sympy",
        "documentation": {}
    },
    {
        "label": "plot",
        "importPath": "sympy",
        "description": "sympy",
        "isExtraImport": true,
        "detail": "sympy",
        "documentation": {}
    },
    {
        "label": "TPOTRegressor",
        "importPath": "tpot",
        "description": "tpot",
        "isExtraImport": true,
        "detail": "tpot",
        "documentation": {}
    },
    {
        "label": "TPOTClassifier",
        "importPath": "tpot",
        "description": "tpot",
        "isExtraImport": true,
        "detail": "tpot",
        "documentation": {}
    },
    {
        "label": "TPOTRegressor",
        "importPath": "tpot",
        "description": "tpot",
        "isExtraImport": true,
        "detail": "tpot",
        "documentation": {}
    },
    {
        "label": "TPOTClassifier",
        "importPath": "tpot",
        "description": "tpot",
        "isExtraImport": true,
        "detail": "tpot",
        "documentation": {}
    },
    {
        "label": "ply.lex",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "TOKEN",
        "importPath": "ply.lex",
        "description": "ply.lex",
        "isExtraImport": true,
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "tokens.definitions",
        "description": "tokens.definitions",
        "isExtraImport": true,
        "detail": "tokens.definitions",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "tokens.data_types",
        "description": "tokens.data_types",
        "isExtraImport": true,
        "detail": "tokens.data_types",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "tokens.manipulations",
        "description": "tokens.manipulations",
        "isExtraImport": true,
        "detail": "tokens.manipulations",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "tokens.sql",
        "description": "tokens.sql",
        "isExtraImport": true,
        "detail": "tokens.sql",
        "documentation": {}
    },
    {
        "label": "traceback",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "traceback",
        "description": "traceback",
        "detail": "traceback",
        "documentation": {}
    },
    {
        "label": "ply.yacc",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "JsonResponse",
        "importPath": "django.http",
        "description": "django.http",
        "isExtraImport": true,
        "detail": "django.http",
        "documentation": {}
    },
    {
        "label": "StreamingHttpResponse",
        "importPath": "django.http",
        "description": "django.http",
        "isExtraImport": true,
        "detail": "django.http",
        "documentation": {}
    },
    {
        "label": "HttpResponse",
        "importPath": "django.http",
        "description": "django.http",
        "isExtraImport": true,
        "detail": "django.http",
        "documentation": {}
    },
    {
        "label": "render",
        "importPath": "django.shortcuts",
        "description": "django.shortcuts",
        "isExtraImport": true,
        "detail": "django.shortcuts",
        "documentation": {}
    },
    {
        "label": "render",
        "importPath": "django.shortcuts",
        "description": "django.shortcuts",
        "isExtraImport": true,
        "detail": "django.shortcuts",
        "documentation": {}
    },
    {
        "label": "csrf_exempt",
        "importPath": "django.views.decorators.csrf",
        "description": "django.views.decorators.csrf",
        "isExtraImport": true,
        "detail": "django.views.decorators.csrf",
        "documentation": {}
    },
    {
        "label": "api_view",
        "importPath": "rest_framework.decorators",
        "description": "rest_framework.decorators",
        "isExtraImport": true,
        "detail": "rest_framework.decorators",
        "documentation": {}
    },
    {
        "label": "settings",
        "importPath": "django.conf",
        "description": "django.conf",
        "isExtraImport": true,
        "detail": "django.conf",
        "documentation": {}
    },
    {
        "label": "get_asgi_application",
        "importPath": "django.core.asgi",
        "description": "django.core.asgi",
        "isExtraImport": true,
        "detail": "django.core.asgi",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "admin",
        "importPath": "django.contrib",
        "description": "django.contrib",
        "isExtraImport": true,
        "detail": "django.contrib",
        "documentation": {}
    },
    {
        "label": "path",
        "importPath": "django.urls",
        "description": "django.urls",
        "isExtraImport": true,
        "detail": "django.urls",
        "documentation": {}
    },
    {
        "label": "test_view",
        "importPath": "backend_app.views",
        "description": "backend_app.views",
        "isExtraImport": true,
        "detail": "backend_app.views",
        "documentation": {}
    },
    {
        "label": "get_wsgi_application",
        "importPath": "django.core.wsgi",
        "description": "django.core.wsgi",
        "isExtraImport": true,
        "detail": "django.core.wsgi",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "_Known",
        "kind": 6,
        "importPath": "client.node_modules.flatted.python.flatted",
        "description": "client.node_modules.flatted.python.flatted",
        "peekOfCode": "class _Known:\n    def __init__(self):\n        self.key = []\n        self.value = []\nclass _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0",
        "detail": "client.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "_String",
        "kind": 6,
        "importPath": "client.node_modules.flatted.python.flatted",
        "description": "client.node_modules.flatted.python.flatted",
        "peekOfCode": "class _String:\n    def __init__(self, value):\n        self.value = value\ndef _array_keys(value):\n    keys = []\n    i = 0\n    for _ in value:\n        keys.append(i)\n        i += 1\n    return keys",
        "detail": "client.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "parse",
        "kind": 2,
        "importPath": "client.node_modules.flatted.python.flatted",
        "description": "client.node_modules.flatted.python.flatted",
        "peekOfCode": "def parse(value, *args, **kwargs):\n    json = _json.loads(value, *args, **kwargs)\n    wrapped = []\n    for value in json:\n        wrapped.append(_wrap(value))\n    input = []\n    for value in wrapped:\n        if isinstance(value, _String):\n            input.append(value.value)\n        else:",
        "detail": "client.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "stringify",
        "kind": 2,
        "importPath": "client.node_modules.flatted.python.flatted",
        "description": "client.node_modules.flatted.python.flatted",
        "peekOfCode": "def stringify(value, *args, **kwargs):\n    known = _Known()\n    input = []\n    output = []\n    i = int(_index(known, input, value))\n    while i < len(input):\n        output.append(_transform(known, input, input[i]))\n        i += 1\n    return _json.dumps(output, *args, **kwargs)",
        "detail": "client.node_modules.flatted.python.flatted",
        "documentation": {}
    },
    {
        "label": "stringify",
        "kind": 2,
        "importPath": "client.node_modules.flatted.python.test",
        "description": "client.node_modules.flatted.python.test",
        "peekOfCode": "def stringify(value):\n    return _stringify(value, separators=(',', ':'))\nassert stringify([None, None]) == '[[null,null]]'\na = []\no = {}\nassert stringify(a) == '[[]]'\nassert stringify(o) == '[{}]'\na.append(a)\no['o'] = o\nassert stringify(a) == '[[\"0\"]]'",
        "detail": "client.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "a",
        "kind": 5,
        "importPath": "client.node_modules.flatted.python.test",
        "description": "client.node_modules.flatted.python.test",
        "peekOfCode": "a = []\no = {}\nassert stringify(a) == '[[]]'\nassert stringify(o) == '[{}]'\na.append(a)\no['o'] = o\nassert stringify(a) == '[[\"0\"]]'\nassert stringify(o) == '[{\"o\":\"0\"}]'\nb = parse(stringify(a))\nassert isinstance(b, list) and b[0] == b",
        "detail": "client.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o",
        "kind": 5,
        "importPath": "client.node_modules.flatted.python.test",
        "description": "client.node_modules.flatted.python.test",
        "peekOfCode": "o = {}\nassert stringify(a) == '[[]]'\nassert stringify(o) == '[{}]'\na.append(a)\no['o'] = o\nassert stringify(a) == '[[\"0\"]]'\nassert stringify(o) == '[{\"o\":\"0\"}]'\nb = parse(stringify(a))\nassert isinstance(b, list) and b[0] == b\na.append(1)",
        "detail": "client.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['o']",
        "kind": 5,
        "importPath": "client.node_modules.flatted.python.test",
        "description": "client.node_modules.flatted.python.test",
        "peekOfCode": "o['o'] = o\nassert stringify(a) == '[[\"0\"]]'\nassert stringify(o) == '[{\"o\":\"0\"}]'\nb = parse(stringify(a))\nassert isinstance(b, list) and b[0] == b\na.append(1)\na.append('two')\na.append(True)\no['one'] = 1\no['two'] = 'two'",
        "detail": "client.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "b",
        "kind": 5,
        "importPath": "client.node_modules.flatted.python.test",
        "description": "client.node_modules.flatted.python.test",
        "peekOfCode": "b = parse(stringify(a))\nassert isinstance(b, list) and b[0] == b\na.append(1)\na.append('two')\na.append(True)\no['one'] = 1\no['two'] = 'two'\no['three'] = True\nassert stringify(a) == '[[\"0\",1,\"1\",true],\"two\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true},\"two\"]'",
        "detail": "client.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['one']",
        "kind": 5,
        "importPath": "client.node_modules.flatted.python.test",
        "description": "client.node_modules.flatted.python.test",
        "peekOfCode": "o['one'] = 1\no['two'] = 'two'\no['three'] = True\nassert stringify(a) == '[[\"0\",1,\"1\",true],\"two\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true},\"two\"]'\na.append(o)\no['a'] = a\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\"}]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\"},\"two\",[\"2\",1,\"1\",true,\"0\"]]'\na.append({'test': 'OK'})",
        "detail": "client.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['two']",
        "kind": 5,
        "importPath": "client.node_modules.flatted.python.test",
        "description": "client.node_modules.flatted.python.test",
        "peekOfCode": "o['two'] = 'two'\no['three'] = True\nassert stringify(a) == '[[\"0\",1,\"1\",true],\"two\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true},\"two\"]'\na.append(o)\no['a'] = a\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\"}]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\"},\"two\",[\"2\",1,\"1\",true,\"0\"]]'\na.append({'test': 'OK'})\na.append([1, 2, 3])",
        "detail": "client.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['three']",
        "kind": 5,
        "importPath": "client.node_modules.flatted.python.test",
        "description": "client.node_modules.flatted.python.test",
        "peekOfCode": "o['three'] = True\nassert stringify(a) == '[[\"0\",1,\"1\",true],\"two\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true},\"two\"]'\na.append(o)\no['a'] = a\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\"}]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\"},\"two\",[\"2\",1,\"1\",true,\"0\"]]'\na.append({'test': 'OK'})\na.append([1, 2, 3])\no['test'] = {'test': 'OK'}",
        "detail": "client.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['a']",
        "kind": 5,
        "importPath": "client.node_modules.flatted.python.test",
        "description": "client.node_modules.flatted.python.test",
        "peekOfCode": "o['a'] = a\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\"}]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\"},\"two\",[\"2\",1,\"1\",true,\"0\"]]'\na.append({'test': 'OK'})\na.append([1, 2, 3])\no['test'] = {'test': 'OK'}\no['array'] = [1, 2, 3]\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\",\"3\",\"4\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\",\"test\":\"3\",\"array\":\"4\"},{\"test\":\"5\"},[1,2,3],\"OK\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\",\"test\":\"3\",\"array\":\"4\"},\"two\",[\"2\",1,\"1\",true,\"0\",\"3\",\"4\"],{\"test\":\"5\"},[1,2,3],\"OK\"]'\na2 = parse(stringify(a));",
        "detail": "client.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['test']",
        "kind": 5,
        "importPath": "client.node_modules.flatted.python.test",
        "description": "client.node_modules.flatted.python.test",
        "peekOfCode": "o['test'] = {'test': 'OK'}\no['array'] = [1, 2, 3]\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\",\"3\",\"4\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\",\"test\":\"3\",\"array\":\"4\"},{\"test\":\"5\"},[1,2,3],\"OK\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\",\"test\":\"3\",\"array\":\"4\"},\"two\",[\"2\",1,\"1\",true,\"0\",\"3\",\"4\"],{\"test\":\"5\"},[1,2,3],\"OK\"]'\na2 = parse(stringify(a));\no2 = parse(stringify(o));\nassert a2[0] == a2\nassert o2['o'] == o2\nassert a2[1] == 1 and a2[2] == 'two' and a2[3] == True and isinstance(a2[4], dict)\nassert a2[4] == a2[4]['o'] and a2 == a2[4]['o']['a']",
        "detail": "client.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o['array']",
        "kind": 5,
        "importPath": "client.node_modules.flatted.python.test",
        "description": "client.node_modules.flatted.python.test",
        "peekOfCode": "o['array'] = [1, 2, 3]\nassert stringify(a) == '[[\"0\",1,\"1\",true,\"2\",\"3\",\"4\"],\"two\",{\"o\":\"2\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"0\",\"test\":\"3\",\"array\":\"4\"},{\"test\":\"5\"},[1,2,3],\"OK\"]'\nassert stringify(o) == '[{\"o\":\"0\",\"one\":1,\"two\":\"1\",\"three\":true,\"a\":\"2\",\"test\":\"3\",\"array\":\"4\"},\"two\",[\"2\",1,\"1\",true,\"0\",\"3\",\"4\"],{\"test\":\"5\"},[1,2,3],\"OK\"]'\na2 = parse(stringify(a));\no2 = parse(stringify(o));\nassert a2[0] == a2\nassert o2['o'] == o2\nassert a2[1] == 1 and a2[2] == 'two' and a2[3] == True and isinstance(a2[4], dict)\nassert a2[4] == a2[4]['o'] and a2 == a2[4]['o']['a']\nstr = parse('[{\"prop\":\"1\",\"a\":\"2\",\"b\":\"3\"},{\"value\":123},[\"4\",\"5\"],{\"e\":\"6\",\"t\":\"7\",\"p\":4},{},{\"b\":\"8\"},\"f\",{\"a\":\"9\"},[\"10\"],\"sup\",{\"a\":1,\"d\":2,\"c\":\"7\",\"z\":\"11\",\"h\":1},{\"g\":2,\"a\":\"7\",\"b\":\"12\",\"f\":6},{\"r\":4,\"u\":\"7\",\"c\":5}]')",
        "detail": "client.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "a2",
        "kind": 5,
        "importPath": "client.node_modules.flatted.python.test",
        "description": "client.node_modules.flatted.python.test",
        "peekOfCode": "a2 = parse(stringify(a));\no2 = parse(stringify(o));\nassert a2[0] == a2\nassert o2['o'] == o2\nassert a2[1] == 1 and a2[2] == 'two' and a2[3] == True and isinstance(a2[4], dict)\nassert a2[4] == a2[4]['o'] and a2 == a2[4]['o']['a']\nstr = parse('[{\"prop\":\"1\",\"a\":\"2\",\"b\":\"3\"},{\"value\":123},[\"4\",\"5\"],{\"e\":\"6\",\"t\":\"7\",\"p\":4},{},{\"b\":\"8\"},\"f\",{\"a\":\"9\"},[\"10\"],\"sup\",{\"a\":1,\"d\":2,\"c\":\"7\",\"z\":\"11\",\"h\":1},{\"g\":2,\"a\":\"7\",\"b\":\"12\",\"f\":6},{\"r\":4,\"u\":\"7\",\"c\":5}]')\nassert str['b']['t']['a'] == 'sup' and str['a'][1]['b'][0]['c'] == str['b']['t']\noo = parse('[{\"a\":\"1\",\"b\":\"0\",\"c\":\"2\"},{\"aa\":\"3\"},{\"ca\":\"4\",\"cb\":\"5\",\"cc\":\"6\",\"cd\":\"7\",\"ce\":\"8\",\"cf\":\"9\"},{\"aaa\":\"10\"},{\"caa\":\"4\"},{\"cba\":\"5\"},{\"cca\":\"2\"},{\"cda\":\"4\"},\"value2\",\"value3\",\"value1\"]');\nassert oo['a']['aa']['aaa'] == 'value1' and oo == oo['b'] and oo['c']['ca']['caa'] == oo['c']['ca']",
        "detail": "client.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "o2",
        "kind": 5,
        "importPath": "client.node_modules.flatted.python.test",
        "description": "client.node_modules.flatted.python.test",
        "peekOfCode": "o2 = parse(stringify(o));\nassert a2[0] == a2\nassert o2['o'] == o2\nassert a2[1] == 1 and a2[2] == 'two' and a2[3] == True and isinstance(a2[4], dict)\nassert a2[4] == a2[4]['o'] and a2 == a2[4]['o']['a']\nstr = parse('[{\"prop\":\"1\",\"a\":\"2\",\"b\":\"3\"},{\"value\":123},[\"4\",\"5\"],{\"e\":\"6\",\"t\":\"7\",\"p\":4},{},{\"b\":\"8\"},\"f\",{\"a\":\"9\"},[\"10\"],\"sup\",{\"a\":1,\"d\":2,\"c\":\"7\",\"z\":\"11\",\"h\":1},{\"g\":2,\"a\":\"7\",\"b\":\"12\",\"f\":6},{\"r\":4,\"u\":\"7\",\"c\":5}]')\nassert str['b']['t']['a'] == 'sup' and str['a'][1]['b'][0]['c'] == str['b']['t']\noo = parse('[{\"a\":\"1\",\"b\":\"0\",\"c\":\"2\"},{\"aa\":\"3\"},{\"ca\":\"4\",\"cb\":\"5\",\"cc\":\"6\",\"cd\":\"7\",\"ce\":\"8\",\"cf\":\"9\"},{\"aaa\":\"10\"},{\"caa\":\"4\"},{\"cba\":\"5\"},{\"cca\":\"2\"},{\"cda\":\"4\"},\"value2\",\"value3\",\"value1\"]');\nassert oo['a']['aa']['aaa'] == 'value1' and oo == oo['b'] and oo['c']['ca']['caa'] == oo['c']['ca']\nprint('OK')",
        "detail": "client.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "str",
        "kind": 5,
        "importPath": "client.node_modules.flatted.python.test",
        "description": "client.node_modules.flatted.python.test",
        "peekOfCode": "str = parse('[{\"prop\":\"1\",\"a\":\"2\",\"b\":\"3\"},{\"value\":123},[\"4\",\"5\"],{\"e\":\"6\",\"t\":\"7\",\"p\":4},{},{\"b\":\"8\"},\"f\",{\"a\":\"9\"},[\"10\"],\"sup\",{\"a\":1,\"d\":2,\"c\":\"7\",\"z\":\"11\",\"h\":1},{\"g\":2,\"a\":\"7\",\"b\":\"12\",\"f\":6},{\"r\":4,\"u\":\"7\",\"c\":5}]')\nassert str['b']['t']['a'] == 'sup' and str['a'][1]['b'][0]['c'] == str['b']['t']\noo = parse('[{\"a\":\"1\",\"b\":\"0\",\"c\":\"2\"},{\"aa\":\"3\"},{\"ca\":\"4\",\"cb\":\"5\",\"cc\":\"6\",\"cd\":\"7\",\"ce\":\"8\",\"cf\":\"9\"},{\"aaa\":\"10\"},{\"caa\":\"4\"},{\"cba\":\"5\"},{\"cca\":\"2\"},{\"cda\":\"4\"},\"value2\",\"value3\",\"value1\"]');\nassert oo['a']['aa']['aaa'] == 'value1' and oo == oo['b'] and oo['c']['ca']['caa'] == oo['c']['ca']\nprint('OK')",
        "detail": "client.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "oo",
        "kind": 5,
        "importPath": "client.node_modules.flatted.python.test",
        "description": "client.node_modules.flatted.python.test",
        "peekOfCode": "oo = parse('[{\"a\":\"1\",\"b\":\"0\",\"c\":\"2\"},{\"aa\":\"3\"},{\"ca\":\"4\",\"cb\":\"5\",\"cc\":\"6\",\"cd\":\"7\",\"ce\":\"8\",\"cf\":\"9\"},{\"aaa\":\"10\"},{\"caa\":\"4\"},{\"cba\":\"5\"},{\"cca\":\"2\"},{\"cda\":\"4\"},\"value2\",\"value3\",\"value1\"]');\nassert oo['a']['aa']['aaa'] == 'value1' and oo == oo['b'] and oo['c']['ca']['caa'] == oo['c']['ca']\nprint('OK')",
        "detail": "client.node_modules.flatted.python.test",
        "documentation": {}
    },
    {
        "label": "db",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.data.db",
        "description": "server.backend_app.mlsql.data.db",
        "peekOfCode": "db = SqliteDatabase('definitions.db')",
        "detail": "server.backend_app.mlsql.data.db",
        "documentation": {}
    },
    {
        "label": "EstimatorMeta",
        "kind": 6,
        "importPath": "server.backend_app.mlsql.data.EstimatorMeta",
        "description": "server.backend_app.mlsql.data.EstimatorMeta",
        "peekOfCode": "class EstimatorMeta(Model):\n    name = CharField(primary_key=True)\n    dateCreated = DateTimeField(default=datetime.datetime.now)\n    isAvailable = BooleanField(default=False)\n    estimatorType = CharField()\n    formula = CharField(null=True)\n    loss = CharField(null=True)\n    lr = FloatField(null=True)\n    optimizer = CharField(null=True)\n    regularizer = CharField(null=True)",
        "detail": "server.backend_app.mlsql.data.EstimatorMeta",
        "documentation": {}
    },
    {
        "label": "setup",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.data.setup",
        "description": "server.backend_app.mlsql.data.setup",
        "peekOfCode": "def setup():\n    tables = [EstimatorMeta, TrainingProfile]\n    db.connect()\n    db.drop_tables(tables)\n    db.create_tables(tables)\n    db.close()\n    print(\"setup complete\")\n    pass",
        "detail": "server.backend_app.mlsql.data.setup",
        "documentation": {}
    },
    {
        "label": "TrainingProfile",
        "kind": 6,
        "importPath": "server.backend_app.mlsql.data.TrainingProfile",
        "description": "server.backend_app.mlsql.data.TrainingProfile",
        "peekOfCode": "class TrainingProfile(Model):\n    name = CharField(primary_key=True)\n    dateCreated = DateTimeField(default=datetime.datetime.now)\n    source = CharField()\n    sourceType = CharField(default='sql')\n    validationSplit = FloatField(default=0)\n    batchSize = IntegerField(default=0)\n    epoch = IntegerField(default=1)\n    shuffle = BooleanField(default=False)\n    class Meta:",
        "detail": "server.backend_app.mlsql.data.TrainingProfile",
        "documentation": {}
    },
    {
        "label": "ASTProcessor",
        "kind": 6,
        "importPath": "server.backend_app.mlsql.engine.ASTProcessor",
        "description": "server.backend_app.mlsql.engine.ASTProcessor",
        "peekOfCode": "class ASTProcessor:\n    def __init__(self):\n        self.pp = pprint.PrettyPrinter(indent=3)\n        pass\n    def hasDB(self, dbURL, dbEngine='sqlite3'):\n        if dbEngine == 'sqlite3':\n            try:\n                open(dbURL, 'r')\n                return True\n            except FileNotFoundError:",
        "detail": "server.backend_app.mlsql.engine.ASTProcessor",
        "documentation": {}
    },
    {
        "label": "EstimatorManager",
        "kind": 6,
        "importPath": "server.backend_app.mlsql.engine.EstimatorManager",
        "description": "server.backend_app.mlsql.engine.EstimatorManager",
        "peekOfCode": "class EstimatorManager:\n    def __init__(self, clonable):\n        self.clonable = clonable\n        current_directory = os.path.dirname(__file__)\n        self.estimator_folder =  os.path.join(current_directory, \"estimators/\")\n    def getPath(self, estimatorName):\n        return self.estimator_folder + estimatorName + \".dill\"\n    def save(self, name, estimator):\n        fname = self.getPath(name)\n        with open(fname, \"wb\") as fp:",
        "detail": "server.backend_app.mlsql.engine.EstimatorManager",
        "documentation": {}
    },
    {
        "label": "FormulaProcessor",
        "kind": 6,
        "importPath": "server.backend_app.mlsql.engine.FormulaProcessor",
        "description": "server.backend_app.mlsql.engine.FormulaProcessor",
        "peekOfCode": "class FormulaProcessor:\n    def __init__(self, formula):\n            #  ~RAD + AGE,TAX~\n        self.formula = formula\n        yX = self.stringFilter(re.split(r'\\~+', self.formula))\n        if len(yX) != 2:\n            raise Exception(f\"{formula} does not have $a~b$ format\")\n        self.fieldY = yX[0]\n        self.formulaX = yX[1]\n        self.fieldsX = self.stringFilter(re.split(r'\\++', self.formulaX))",
        "detail": "server.backend_app.mlsql.engine.FormulaProcessor",
        "documentation": {}
    },
    {
        "label": "SimpleKNNClassifier",
        "kind": 6,
        "importPath": "server.backend_app.mlsql.engine.KNN",
        "description": "server.backend_app.mlsql.engine.KNN",
        "peekOfCode": "class SimpleKNNClassifier:\n    def __init__(self, k=3):\n        self.k = k\n        self.X_train = None\n        self.y_train = None\n    def fit(self, X, y):\n        self.X_train = X\n        self.y_train = y\n    def predict(self, X):\n        y_pred = [self._predict(x) for x in X]",
        "detail": "server.backend_app.mlsql.engine.KNN",
        "documentation": {}
    },
    {
        "label": "KNNManager",
        "kind": 6,
        "importPath": "server.backend_app.mlsql.engine.KNN",
        "description": "server.backend_app.mlsql.engine.KNN",
        "peekOfCode": "class KNNManager(RegressionManager):\n    def __init__(self):\n        super().__init__(clonable=True)\n    def create(self, name, k=3):\n        estimator = SimpleKNNClassifier(k=k)\n        return self.save(name, estimator)\n    def trainValidate(self, name, Xtrain, Xtest, yTrain, yTest):\n        dic = {}\n        self.train(name, Xtrain, yTrain)\n        dic['training_accuracy'] = np.mean(yTrain == self.predict(name, Xtrain))",
        "detail": "server.backend_app.mlsql.engine.KNN",
        "documentation": {}
    },
    {
        "label": "LRManager",
        "kind": 6,
        "importPath": "server.backend_app.mlsql.engine.LRManager",
        "description": "server.backend_app.mlsql.engine.LRManager",
        "peekOfCode": "class LRManager(RegressionManager):\n    def __init__(self):\n        super(LRManager,self).__init__(clonable=True)\n    def create(self, name):\n        estimator = LinearRegression()\n        return self.save(name, estimator)\n    def trainValidate(self, name, Xtrain, Xtest, yTrain, yTest):\n        dic = {}\n        self.train(name, Xtrain, yTrain)\n        dic['training_mae'] = median_absolute_error(yTrain, self.predict(name, Xtrain))",
        "detail": "server.backend_app.mlsql.engine.LRManager",
        "documentation": {}
    },
    {
        "label": "RegressionManager",
        "kind": 6,
        "importPath": "server.backend_app.mlsql.engine.RegressionManager",
        "description": "server.backend_app.mlsql.engine.RegressionManager",
        "peekOfCode": "class RegressionManager(EstimatorManager):\n    def __init__(self, clonable):\n        super(RegressionManager,self).__init__(clonable=clonable)\n    def getPercentageError(self, y, yPred):\n        return (y - yPred) * 100 / y\n    def getAccuracy(self, y, yPred):\n        # This method can be added for classification tasks\n        correct_predictions = (y == yPred).sum()\n        total_predictions = len(y)\n        return (correct_predictions / total_predictions) * 100",
        "detail": "server.backend_app.mlsql.engine.RegressionManager",
        "documentation": {}
    },
    {
        "label": "cluster",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.operation.cluster",
        "description": "server.backend_app.mlsql.parser.operation.cluster",
        "peekOfCode": "def cluster(currentDB,conn, n_cluster):\n    query = f\"SELECT * FROM {currentDB}\"\n    df = pd.read_sql_query(query, conn)\n    # Perform clustering\n    X = df.values  # Assuming all columns are features\n    kmeans = KMeans(n_clusters=int(n_cluster))\n    kmeans.fit(X)\n    labels = kmeans.labels_\n    plt.figure(figsize=(8, 6))\n    plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')",
        "detail": "server.backend_app.mlsql.parser.operation.cluster",
        "documentation": {}
    },
    {
        "label": "select_algorithm",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.operation.construct",
        "description": "server.backend_app.mlsql.parser.operation.construct",
        "peekOfCode": "def select_algorithm(operation_type, algorithm_name='default', **kwargs):\n    print(algorithm_name)\n    if algorithm_name == 'default':\n        if operation_type.upper() == \"PREDICTION\":\n            return TPOTRegressor(generations=5, population_size=20, verbosity=2)\n        elif operation_type.upper() == \"CLASSIFICATION\":\n            return TPOTClassifier(generations=5, population_size=20, verbosity=2)\n    else:\n        prediction_algorithms = {\n            \"LR\": LinearRegression(),",
        "detail": "server.backend_app.mlsql.parser.operation.construct",
        "documentation": {}
    },
    {
        "label": "construct",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.operation.construct",
        "description": "server.backend_app.mlsql.parser.operation.construct",
        "peekOfCode": "def construct(command):\n    '''  \n        CONSTRUCT ModelName AS SUPERVISED  ALGORITHM KMeans OF CLUSTERING WITH CLASS 5 FROM Boston;\n        CONSTRUCT ModelName AS SUPERVISED FOR medv FEATURES age,rad ALGORITHM LR OF PREDICTION TEST ON .3 FROM Boston;\n    '''\n    command_parts = command.split()\n    operation_types = [\"PREDICTION\", \"CLASSIFICATION\", \"CLUSTERING\"]\n    operation_type = command_parts[command_parts.index(\"OF\")+ 1]\n    dataset_train_name = command_parts[command_parts.index(\"FROM\") + 1].split(';')[0]\n    model_name=command_parts[command_parts.index(\"CONSTRUCT\") + 1]",
        "detail": "server.backend_app.mlsql.parser.operation.construct",
        "documentation": {}
    },
    {
        "label": "select_algorithm",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.operation.Generate",
        "description": "server.backend_app.mlsql.parser.operation.Generate",
        "peekOfCode": "def select_algorithm(operation_type, algorithm_name='default', **kwargs):\n    print(algorithm_name)\n    if algorithm_name == 'default':\n        if operation_type.upper() == \"PREDICTION\":\n            return TPOTRegressor(generations=5, population_size=20, verbosity=2)\n        elif operation_type.upper() == \"CLASSIFICATION\":\n            return TPOTClassifier(generations=5, population_size=20, verbosity=2)\n    else:\n        prediction_algorithms = {\n            \"LR\": LinearRegression(),",
        "detail": "server.backend_app.mlsql.parser.operation.Generate",
        "documentation": {}
    },
    {
        "label": "display_results",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.operation.Generate",
        "description": "server.backend_app.mlsql.parser.operation.Generate",
        "peekOfCode": "def display_results(operation_type, y_test=None, y_pred=None, model=None, features=None, df=None):\n    if operation_type.upper() == \"PREDICTION\":\n        plt.figure(figsize=(10, 6))\n        plt.scatter(y_test, y_pred, alpha=0.6)\n        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n        plt.xlabel('Measured')\n        plt.ylabel('Predicted')\n        plt.title('Actual vs Predicted Values')\n    elif operation_type.upper() == \"CLASSIFICATION\":\n        cm = confusion_matrix(y_test, y_pred)",
        "detail": "server.backend_app.mlsql.parser.operation.Generate",
        "documentation": {}
    },
    {
        "label": "generate",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.operation.Generate",
        "description": "server.backend_app.mlsql.parser.operation.Generate",
        "peekOfCode": "def generate(command):\n    '''GENERATE DISPLAY OF PREDICTION MonthlySales ALGORITHM GB WITH ACCURACY 100 LABEL ProductID FEATURES Age,Price,StockLevel FROM retail OVER retailTestData'''\n    command_parts = command.split(\" \")\n    try:\n        operation_types = [\"PREDICTION\", \"CLASSIFICATION\", \"CLUSTERING\"]\n        operation_type = next((word for word in operation_types if word in command), \"PREDICTION\") ###\n        dataset_train_name = command_parts[command_parts.index(\"FROM\") + 1].split(';')[0]\n        features=command_parts[command_parts.index(\"FEATURES\") + 1].split(',')\n        algorithm_name = command_parts[command_parts.index(\"ALGORITHM\")+ 1] if \"ALGORITHM\" in command_parts else None  ####\n    except:",
        "detail": "server.backend_app.mlsql.parser.operation.Generate",
        "documentation": {}
    },
    {
        "label": "dataTypeTokens",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.tokens.data_types",
        "description": "server.backend_app.mlsql.parser.tokens.data_types",
        "peekOfCode": "dataTypeTokens = [\n    'WORD',\n    # 'CHAR'\n    'FLOAT',\n    'INT',\n    'DELIMITER',\n    'BOOL',\n    'URL'\n]\n#regular expressions",
        "detail": "server.backend_app.mlsql.parser.tokens.data_types",
        "documentation": {}
    },
    {
        "label": "t_WORD",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.tokens.data_types",
        "description": "server.backend_app.mlsql.parser.tokens.data_types",
        "peekOfCode": "t_WORD = r'[a-zA-Z_][a-zA-Z_0-9]*'\nt_FLOAT = r'[0-9]+\\.[0-9]*|[0-9]*\\.[0-9]+'\nt_INT = r'[0-9]+'\nt_DELIMITER = r';'\n# t_CHAR = r'[a-zA-Z_][a-zA-Z_0-9]*'",
        "detail": "server.backend_app.mlsql.parser.tokens.data_types",
        "documentation": {}
    },
    {
        "label": "t_FLOAT",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.tokens.data_types",
        "description": "server.backend_app.mlsql.parser.tokens.data_types",
        "peekOfCode": "t_FLOAT = r'[0-9]+\\.[0-9]*|[0-9]*\\.[0-9]+'\nt_INT = r'[0-9]+'\nt_DELIMITER = r';'\n# t_CHAR = r'[a-zA-Z_][a-zA-Z_0-9]*'",
        "detail": "server.backend_app.mlsql.parser.tokens.data_types",
        "documentation": {}
    },
    {
        "label": "t_INT",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.tokens.data_types",
        "description": "server.backend_app.mlsql.parser.tokens.data_types",
        "peekOfCode": "t_INT = r'[0-9]+'\nt_DELIMITER = r';'\n# t_CHAR = r'[a-zA-Z_][a-zA-Z_0-9]*'",
        "detail": "server.backend_app.mlsql.parser.tokens.data_types",
        "documentation": {}
    },
    {
        "label": "t_DELIMITER",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.tokens.data_types",
        "description": "server.backend_app.mlsql.parser.tokens.data_types",
        "peekOfCode": "t_DELIMITER = r';'\n# t_CHAR = r'[a-zA-Z_][a-zA-Z_0-9]*'",
        "detail": "server.backend_app.mlsql.parser.tokens.data_types",
        "documentation": {}
    },
    {
        "label": "modelTokens",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.tokens.definitions",
        "description": "server.backend_app.mlsql.parser.tokens.definitions",
        "peekOfCode": "modelTokens = [\n    'CREATE',\n    'CLONE',\n    'MODEL',\n    'ESTIMATOR',\n    'REGULARIZER',\n    'MODEL_TYPE',\n    'FORMULA',\n    'FORMULA_EXP',\n    'LOSS',",
        "detail": "server.backend_app.mlsql.parser.tokens.definitions",
        "documentation": {}
    },
    {
        "label": "trainProfileTokens",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.tokens.definitions",
        "description": "server.backend_app.mlsql.parser.tokens.definitions",
        "peekOfCode": "trainProfileTokens = [\n    'CREATE',\n    'AND',\n    'TRAINING_PROFILE',\n    'BATCH_SIZE',\n    'EPOCH',\n    'SHUFFLE',\n    'VALIDATION_SPLIT',\n    'WITH',\n    'USE',",
        "detail": "server.backend_app.mlsql.parser.tokens.definitions",
        "documentation": {}
    },
    {
        "label": "trainTokens",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.tokens.definitions",
        "description": "server.backend_app.mlsql.parser.tokens.definitions",
        "peekOfCode": "trainTokens = [\n    'TRAIN'\n]\npredictTokens = [\n    'PREDICT',\n    'TEST'\n]\nsqlKeywords = [\n    'TABLE',\n]",
        "detail": "server.backend_app.mlsql.parser.tokens.definitions",
        "documentation": {}
    },
    {
        "label": "predictTokens",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.tokens.definitions",
        "description": "server.backend_app.mlsql.parser.tokens.definitions",
        "peekOfCode": "predictTokens = [\n    'PREDICT',\n    'TEST'\n]\nsqlKeywords = [\n    'TABLE',\n]",
        "detail": "server.backend_app.mlsql.parser.tokens.definitions",
        "documentation": {}
    },
    {
        "label": "sqlKeywords",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.tokens.definitions",
        "description": "server.backend_app.mlsql.parser.tokens.definitions",
        "peekOfCode": "sqlKeywords = [\n    'TABLE',\n]",
        "detail": "server.backend_app.mlsql.parser.tokens.definitions",
        "documentation": {}
    },
    {
        "label": "trainTokens",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.tokens.manipulations",
        "description": "server.backend_app.mlsql.parser.tokens.manipulations",
        "peekOfCode": "trainTokens = [\n    'TRAIN',\n    'WITH',\n    'TRAINING_PROFILE'\n]\nutilityTokens = [\n    'SET',\n    'DEBUG',\n    'AS'\n]",
        "detail": "server.backend_app.mlsql.parser.tokens.manipulations",
        "documentation": {}
    },
    {
        "label": "utilityTokens",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.tokens.manipulations",
        "description": "server.backend_app.mlsql.parser.tokens.manipulations",
        "peekOfCode": "utilityTokens = [\n    'SET',\n    'DEBUG',\n    'AS'\n]",
        "detail": "server.backend_app.mlsql.parser.tokens.manipulations",
        "documentation": {}
    },
    {
        "label": "basicSQL",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.tokens.sql",
        "description": "server.backend_app.mlsql.parser.tokens.sql",
        "peekOfCode": "basicSQL = [\n    'SQL'\n]",
        "detail": "server.backend_app.mlsql.parser.tokens.sql",
        "documentation": {}
    },
    {
        "label": "t_BOOL",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "def t_BOOL(t):\n    r'true|false'\n    if t.value == 'true':\n        t.value = True\n    else:\n        t.value = False\n    return t\ndef t_SQL(t):\n    r'\\[\\s*[SELECT,UPDATE]+[^\\];]*\\]'\n    t.value = t.value[1:len(t.value)-1].strip()",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "t_SQL",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "def t_SQL(t):\n    r'\\[\\s*[SELECT,UPDATE]+[^\\];]*\\]'\n    t.value = t.value[1:len(t.value)-1].strip()\n    return t\ndef t_URL(t):\n    r'\\'[a-z0-9A-Z\\.\\/\\:\\%\\+\\-\\_\\&\\@ ]+\\''\n    t.value = t.value[1:len(t.value)-1].strip()\n    return t\ndef t_FORMULA_EXP(t):\n    r'\\$[a-zA-Z_0-9]+\\~[a-zA-Z_0-9\\+\\-]+\\$'",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "t_URL",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "def t_URL(t):\n    r'\\'[a-z0-9A-Z\\.\\/\\:\\%\\+\\-\\_\\&\\@ ]+\\''\n    t.value = t.value[1:len(t.value)-1].strip()\n    return t\ndef t_FORMULA_EXP(t):\n    r'\\$[a-zA-Z_0-9]+\\~[a-zA-Z_0-9\\+\\-]+\\$'\n    t.value = t.value[1:len(t.value)-1].strip()\n    return t\n# keywords rule\n# reKyewords = \"(\" + \"|\".join(keywords) + \")+[ \\n\\t]{1}\"",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "t_FORMULA_EXP",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "def t_FORMULA_EXP(t):\n    r'\\$[a-zA-Z_0-9]+\\~[a-zA-Z_0-9\\+\\-]+\\$'\n    t.value = t.value[1:len(t.value)-1].strip()\n    return t\n# keywords rule\n# reKyewords = \"(\" + \"|\".join(keywords) + \")+[ \\n\\t]{1}\"\nreKyewords = r'\\b(' + '|'.join(keywords) + r')\\b'\n@TOKEN(reKyewords)\ndef t_KEYWORD(t):\n    # print(f\"found keyword: {t.value}\")",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "t_KEYWORD",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "def t_KEYWORD(t):\n    # print(f\"found keyword: {t.value}\")\n    t.value = t.value.strip()\n    t.type = t.value\n    return t\n# Define a rule so we can track line numbers\ndef t_newline(t):\n    r'\\n+'\n    t.lexer.lineno += len(t.value)\ndef t_TRAINING_PROFILE(t):",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "t_newline",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "def t_newline(t):\n    r'\\n+'\n    t.lexer.lineno += len(t.value)\ndef t_TRAINING_PROFILE(t):\n    r'TRAINING[_ \\t\\n]+PROFILE'\n    t.type = 'TRAINING_PROFILE'\n    t.value = 'TRAINING_PROFILE'\n    # print(\"found t_TRAINING_PROFILE\")\n    return t\ndef t_LEARNING_RATE(t):",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "t_TRAINING_PROFILE",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "def t_TRAINING_PROFILE(t):\n    r'TRAINING[_ \\t\\n]+PROFILE'\n    t.type = 'TRAINING_PROFILE'\n    t.value = 'TRAINING_PROFILE'\n    # print(\"found t_TRAINING_PROFILE\")\n    return t\ndef t_LEARNING_RATE(t):\n    r'LEARNING[_ \\t\\n]+RATE'\n    t.type = 'LEARNING_RATE'\n    t.value = 'LEARNING_RATE'",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "t_LEARNING_RATE",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "def t_LEARNING_RATE(t):\n    r'LEARNING[_ \\t\\n]+RATE'\n    t.type = 'LEARNING_RATE'\n    t.value = 'LEARNING_RATE'\n    # print(\"found t_LEARNING_RATE\")\n    return t\ndef t_VALIDATION_SPLIT(t):\n    r'VALIDATION[_ \\t\\n]+SPLIT'\n    t.type = 'VALIDATION_SPLIT'\n    t.value = 'VALIDATION_SPLIT'",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "t_VALIDATION_SPLIT",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "def t_VALIDATION_SPLIT(t):\n    r'VALIDATION[_ \\t\\n]+SPLIT'\n    t.type = 'VALIDATION_SPLIT'\n    t.value = 'VALIDATION_SPLIT'\n    # print(\"found t_VALIDATION_SPLIT\")\n    return t\ndef t_FORMULA_OPERATOR(t):\n    r'~'\n    t.type = 'FORMULA_OPERATOR'\n    t.value = 'FORMULA_OPERATOR'",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "t_FORMULA_OPERATOR",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "def t_FORMULA_OPERATOR(t):\n    r'~'\n    t.type = 'FORMULA_OPERATOR'\n    t.value = 'FORMULA_OPERATOR'\n    # print(\"found t_FORMULA_OPERATOR\")\n    return t\n# A string containing ignored characters (spaces and tabs)\nt_ignore  = ' \\t'\n# Error handling rule\ndef t_error(t):",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "t_error",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "def t_error(t):\n    print(\"Illegal character '%s'\" % t.value[0])\n    t.lexer.skip(1)\nlexer = lex.lex()\ncurrent_directory = os.path.dirname(__file__)\ncurrentDBURL = os.path.join(current_directory,\"lexer.dill\")\nwith open(currentDBURL, \"wb\") as f:\n    dill.dump(lexer, f)",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "dataTypeTokens",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "dataTypeTokens = [\n    'WORD',\n    # 'CHAR'\n    'FLOAT',\n    'INT',\n    'DELIMITER',\n    'BOOL',\n    'URL'\n]\n#regular expressions",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "t_WORD",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "t_WORD = r'[a-zA-Z_][a-zA-Z_0-9]*'\nt_FLOAT = r'[0-9]+\\.[0-9]*|[0-9]*\\.[0-9]+'\nt_INT = r'[0-9]+'\nt_DELIMITER = r';'\n# t_CHAR = r'[a-zA-Z_][a-zA-Z_0-9]*'\ntrainTokens = [\n    'TRAIN',\n    'WITH',\n    'TRAINING_PROFILE'\n]",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "t_FLOAT",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "t_FLOAT = r'[0-9]+\\.[0-9]*|[0-9]*\\.[0-9]+'\nt_INT = r'[0-9]+'\nt_DELIMITER = r';'\n# t_CHAR = r'[a-zA-Z_][a-zA-Z_0-9]*'\ntrainTokens = [\n    'TRAIN',\n    'WITH',\n    'TRAINING_PROFILE'\n]\nutilityTokens = [",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "t_INT",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "t_INT = r'[0-9]+'\nt_DELIMITER = r';'\n# t_CHAR = r'[a-zA-Z_][a-zA-Z_0-9]*'\ntrainTokens = [\n    'TRAIN',\n    'WITH',\n    'TRAINING_PROFILE'\n]\nutilityTokens = [\n    'SET',",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "t_DELIMITER",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "t_DELIMITER = r';'\n# t_CHAR = r'[a-zA-Z_][a-zA-Z_0-9]*'\ntrainTokens = [\n    'TRAIN',\n    'WITH',\n    'TRAINING_PROFILE'\n]\nutilityTokens = [\n    'SET',\n    'DEBUG',",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "trainTokens",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "trainTokens = [\n    'TRAIN',\n    'WITH',\n    'TRAINING_PROFILE'\n]\nutilityTokens = [\n    'SET',\n    'DEBUG',\n    'AS'\n]",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "utilityTokens",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "utilityTokens = [\n    'SET',\n    'DEBUG',\n    'AS'\n]\nmodelTokens = [\n    'CREATE',\n    'CLONE',\n    'MODEL',\n    'ESTIMATOR',",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "modelTokens",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "modelTokens = [\n    'CREATE',\n    'CLONE',\n    'MODEL',\n    'ESTIMATOR',\n    'REGULARIZER',\n    'MODEL_TYPE',\n    'FORMULA',\n    'FORMULA_EXP',\n    'LOSS',",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "trainProfileTokens",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "trainProfileTokens = [\n    'CREATE',\n    'AND',\n    'TRAINING_PROFILE',\n    'BATCH_SIZE',\n    'EPOCH',\n    'SHUFFLE',\n    'VALIDATION_SPLIT',\n    'WITH',\n    'USE',",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "trainTokens",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "trainTokens = [\n    'TRAIN'\n]\npredictTokens = [\n    'PREDICT',\n    'TEST'\n]\nsqlKeywords = [\n    'TABLE',\n]",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "predictTokens",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "predictTokens = [\n    'PREDICT',\n    'TEST'\n]\nsqlKeywords = [\n    'TABLE',\n]\n#-------modified end ----------\nkeywords = list(set().union(\n            modelTokens,",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "sqlKeywords",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "sqlKeywords = [\n    'TABLE',\n]\n#-------modified end ----------\nkeywords = list(set().union(\n            modelTokens,\n            trainTokens,\n            trainProfileTokens,\n            predictTokens,\n            utilityTokens,",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "keywords",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "keywords = list(set().union(\n            modelTokens,\n            trainTokens,\n            trainProfileTokens,\n            predictTokens,\n            utilityTokens,\n            sqlKeywords\n            ))\ntokens =  list(set().union(\n            dataTypeTokens,",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "tokens",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "tokens =  list(set().union(\n            dataTypeTokens,\n            basicSQL\n            )) + keywords\ntokens += ['LPAREN', 'RPAREN']\nt_LPAREN = r'\\('\nt_RPAREN = r'\\)'\n# print(tokens)\ndef t_BOOL(t):\n    r'true|false'",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "t_LPAREN",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "t_LPAREN = r'\\('\nt_RPAREN = r'\\)'\n# print(tokens)\ndef t_BOOL(t):\n    r'true|false'\n    if t.value == 'true':\n        t.value = True\n    else:\n        t.value = False\n    return t",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "t_RPAREN",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "t_RPAREN = r'\\)'\n# print(tokens)\ndef t_BOOL(t):\n    r'true|false'\n    if t.value == 'true':\n        t.value = True\n    else:\n        t.value = False\n    return t\ndef t_SQL(t):",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "reKyewords",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "reKyewords = r'\\b(' + '|'.join(keywords) + r')\\b'\n@TOKEN(reKyewords)\ndef t_KEYWORD(t):\n    # print(f\"found keyword: {t.value}\")\n    t.value = t.value.strip()\n    t.type = t.value\n    return t\n# Define a rule so we can track line numbers\ndef t_newline(t):\n    r'\\n+'",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "lexer",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "lexer = lex.lex()\ncurrent_directory = os.path.dirname(__file__)\ncurrentDBURL = os.path.join(current_directory,\"lexer.dill\")\nwith open(currentDBURL, \"wb\") as f:\n    dill.dump(lexer, f)",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "current_directory",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "current_directory = os.path.dirname(__file__)\ncurrentDBURL = os.path.join(current_directory,\"lexer.dill\")\nwith open(currentDBURL, \"wb\") as f:\n    dill.dump(lexer, f)",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "currentDBURL",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.lexer",
        "description": "server.backend_app.mlsql.parser.lexer",
        "peekOfCode": "currentDBURL = os.path.join(current_directory,\"lexer.dill\")\nwith open(currentDBURL, \"wb\") as f:\n    dill.dump(lexer, f)",
        "detail": "server.backend_app.mlsql.parser.lexer",
        "documentation": {}
    },
    {
        "label": "LexerBuilder",
        "kind": 6,
        "importPath": "server.backend_app.mlsql.parser.LexerBuilder_del",
        "description": "server.backend_app.mlsql.parser.LexerBuilder_del",
        "peekOfCode": "class LexerBuilder:\n    tokens = ()\n    def __init__(self):\n        LexerBuilder.tokens = list(set().union(\n            modelTokens,\n            dataTypeTokens,\n            trainTokens,\n            trainProfileTokens,\n            basicSQL\n            ))",
        "detail": "server.backend_app.mlsql.parser.LexerBuilder_del",
        "documentation": {}
    },
    {
        "label": "setDebug",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.parser",
        "description": "server.backend_app.mlsql.parser.parser",
        "peekOfCode": "def setDebug(debug = False):\n    global DEBUG\n    DEBUG = debug\n#******Environment Setup Ends******\nglobal response\nresponse=''\n#***********Grammar******************\ndef p_create_model(p):\n    '''exp : CREATE ESTIMATOR WORD MODEL_TYPE WORD FORMULA FORMULA_EXP DELIMITER\n            | CREATE ESTIMATOR WORD MODEL_TYPE WORD FORMULA FORMULA_EXP LOSS WORD DELIMITER",
        "detail": "server.backend_app.mlsql.parser.parser",
        "documentation": {}
    },
    {
        "label": "p_create_model",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.parser",
        "description": "server.backend_app.mlsql.parser.parser",
        "peekOfCode": "def p_create_model(p):\n    '''exp : CREATE ESTIMATOR WORD MODEL_TYPE WORD FORMULA FORMULA_EXP DELIMITER\n            | CREATE ESTIMATOR WORD MODEL_TYPE WORD FORMULA FORMULA_EXP LOSS WORD DELIMITER\n            | CREATE ESTIMATOR WORD MODEL_TYPE WORD FORMULA FORMULA_EXP LOSS WORD LEARNING_RATE FLOAT DELIMITER\n            | CREATE ESTIMATOR WORD MODEL_TYPE WORD FORMULA FORMULA_EXP LOSS WORD LEARNING_RATE FLOAT OPTIMIZER WORD REGULARIZER WORD DELIMITER'''\n    setup()\n    printMatchedRule('p_create_model')\n    global currentState, formula\n    currentState = ESTIMATOR\n    length = len(p)",
        "detail": "server.backend_app.mlsql.parser.parser",
        "documentation": {}
    },
    {
        "label": "p_training_profile",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.parser",
        "description": "server.backend_app.mlsql.parser.parser",
        "peekOfCode": "def p_training_profile(p):\n    '''exp : CREATE TRAINING_PROFILE WORD WITH SQL DELIMITER\n                | CREATE TRAINING_PROFILE WORD WITH SQL AND VALIDATION_SPLIT FLOAT DELIMITER\n                | CREATE TRAINING_PROFILE WORD WITH SQL AND VALIDATION_SPLIT FLOAT BATCH_SIZE INT EPOCH INT DELIMITER\n                | CREATE TRAINING_PROFILE WORD WITH SQL AND VALIDATION_SPLIT FLOAT BATCH_SIZE INT EPOCH INT SHUFFLE BOOL DELIMITER'''\n    printMatchedRule('p_training_profile')\n    global currentState\n    currentState = TRAINING_PROFILE\n    length = len(p)\n    name = p[3]",
        "detail": "server.backend_app.mlsql.parser.parser",
        "documentation": {}
    },
    {
        "label": "p_train",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.parser",
        "description": "server.backend_app.mlsql.parser.parser",
        "peekOfCode": "def p_train(p):\n    '''exp : TRAIN WORD WITH WORD DELIMITER\n           | TRAIN WORD WITH TRAINING_PROFILE WORD DELIMITER'''\n    printMatchedRule('p_train')\n    global currentState, currentDB\n    currentState = TRAIN\n    length = len(p)\n    estimatorName = p[2]\n    if length == 6:\n        trainingProfileName = p[4]",
        "detail": "server.backend_app.mlsql.parser.parser",
        "documentation": {}
    },
    {
        "label": "p_predict",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.parser",
        "description": "server.backend_app.mlsql.parser.parser",
        "peekOfCode": "def p_predict(p):\n    '''exp : PREDICT WITH SQL BY ESTIMATOR WORD DELIMITER\n           | PREDICT WITH TRAINING_PROFILE WORD BY ESTIMATOR WORD DELIMITER'''\n    printMatchedRule('p_predict')\n    global currentState, currentDB\n    currentState = PREDICT\n    length = len(p)\n    sql = p[3]\n    estimatorName = p[6]\n    trainingProfileName = None",
        "detail": "server.backend_app.mlsql.parser.parser",
        "documentation": {}
    },
    {
        "label": "p_clone_model",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.parser",
        "description": "server.backend_app.mlsql.parser.parser",
        "peekOfCode": "def p_clone_model(p):\n    '''exp : CLONE ESTIMATOR WORD AS WORD DELIMITER\n           | CLONE ESTIMATOR WORD AS WORD WITH WEIGHTS DELIMITER'''\n    printMatchedRule('p_clone_model')\n    global currentState\n    currentState = ESTIMATOR\n    length = len(p)\n    fromName = p[3]\n    toName = p[5]\n    keepWeights = False",
        "detail": "server.backend_app.mlsql.parser.parser",
        "documentation": {}
    },
    {
        "label": "p_use_database",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.parser",
        "description": "server.backend_app.mlsql.parser.parser",
        "peekOfCode": "def p_use_database(p):\n    'exp : USE URL DELIMITER'\n    printMatchedRule('p_use_database')\n    global currentDB, response\n    current_directory = os.path.dirname(__file__)\n    currentDBURL = os.path.join(current_directory,f'../{p[2]}')\n    if ASTProcessor.hasDB(currentDBURL):\n        print(f\"selected {currentDBURL}\")\n        response = {'text': f\"selected {p[2]}\"}\n        currentDB = ASTProcessor.getDB(currentDBURL)",
        "detail": "server.backend_app.mlsql.parser.parser",
        "documentation": {}
    },
    {
        "label": "p_SQL",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.parser",
        "description": "server.backend_app.mlsql.parser.parser",
        "peekOfCode": "def p_SQL(p):\n    'exp : SQL DELIMITER'\n    printMatchedRule('p_SQL')\n    p[0] = p[1]\n    print( f\" p[0] = {p[0]}\" )\n    pass\ndef p_DEBUG(p):\n    'exp : SET DEBUG BOOL DELIMITER'\n    printMatchedRule('p_DEBUG')\n    global DEBUG",
        "detail": "server.backend_app.mlsql.parser.parser",
        "documentation": {}
    },
    {
        "label": "p_DEBUG",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.parser",
        "description": "server.backend_app.mlsql.parser.parser",
        "peekOfCode": "def p_DEBUG(p):\n    'exp : SET DEBUG BOOL DELIMITER'\n    printMatchedRule('p_DEBUG')\n    global DEBUG\n    DEBUG = p[3]\n    # if p[3] == 'true':\n    #     DEBUG = True\n    # else:\n    #     DEBUG = False\n    print(f\"Debug set to {p[3]}\")",
        "detail": "server.backend_app.mlsql.parser.parser",
        "documentation": {}
    },
    {
        "label": "p_error",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.parser",
        "description": "server.backend_app.mlsql.parser.parser",
        "peekOfCode": "def p_error(t):\n    printError('Syntax error at \"%s\"' % t.value if t else 'NULL')\n    global current_state\n    current_state = None\n    pass\ndef printError(e):\n    global DEBUG\n    print(\"Error:\", end=\" \")\n    print(e)\n    if DEBUG:",
        "detail": "server.backend_app.mlsql.parser.parser",
        "documentation": {}
    },
    {
        "label": "printError",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.parser",
        "description": "server.backend_app.mlsql.parser.parser",
        "peekOfCode": "def printError(e):\n    global DEBUG\n    print(\"Error:\", end=\" \")\n    print(e)\n    if DEBUG:\n        print(\"strack trace:\")\n        for line in traceback.format_stack():\n            print(line.strip())\ndef printMatchedRule(rule):\n    if DEBUG:",
        "detail": "server.backend_app.mlsql.parser.parser",
        "documentation": {}
    },
    {
        "label": "printMatchedRule",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.parser",
        "description": "server.backend_app.mlsql.parser.parser",
        "peekOfCode": "def printMatchedRule(rule):\n    if DEBUG:\n        print(f\"Matched Grammar Rule: {rule}\")\n#***********Grammar Ends******************\n# parser = yacc.yacc(debug=True, errorlog=log)\nparser = yacc.yacc(debug=True)\n# with open(\"parser/parser.dill\", \"wb\") as f:\n#     dill.dump(parser, f)\n# def welcome():\n#     print(f'''",
        "detail": "server.backend_app.mlsql.parser.parser",
        "documentation": {}
    },
    {
        "label": "ASTProcessor",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.parser",
        "description": "server.backend_app.mlsql.parser.parser",
        "peekOfCode": "ASTProcessor = ASTProcessor()\nESTIMATOR, TRAIN, TRAINING_PROFILE, USE, PREDICT = range(5)\nstates = ['ESTIMATOR', 'TRAIN', 'TRAINING_PROFILE', 'USE', 'PREDICT' ]\ncurrentState = None\ncurrentDB = None #database connector instance, not url.\nDEBUG = True\ndef setDebug(debug = False):\n    global DEBUG\n    DEBUG = debug\n#******Environment Setup Ends******",
        "detail": "server.backend_app.mlsql.parser.parser",
        "documentation": {}
    },
    {
        "label": "states",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.parser",
        "description": "server.backend_app.mlsql.parser.parser",
        "peekOfCode": "states = ['ESTIMATOR', 'TRAIN', 'TRAINING_PROFILE', 'USE', 'PREDICT' ]\ncurrentState = None\ncurrentDB = None #database connector instance, not url.\nDEBUG = True\ndef setDebug(debug = False):\n    global DEBUG\n    DEBUG = debug\n#******Environment Setup Ends******\nglobal response\nresponse=''",
        "detail": "server.backend_app.mlsql.parser.parser",
        "documentation": {}
    },
    {
        "label": "currentState",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.parser",
        "description": "server.backend_app.mlsql.parser.parser",
        "peekOfCode": "currentState = None\ncurrentDB = None #database connector instance, not url.\nDEBUG = True\ndef setDebug(debug = False):\n    global DEBUG\n    DEBUG = debug\n#******Environment Setup Ends******\nglobal response\nresponse=''\n#***********Grammar******************",
        "detail": "server.backend_app.mlsql.parser.parser",
        "documentation": {}
    },
    {
        "label": "currentDB",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.parser",
        "description": "server.backend_app.mlsql.parser.parser",
        "peekOfCode": "currentDB = None #database connector instance, not url.\nDEBUG = True\ndef setDebug(debug = False):\n    global DEBUG\n    DEBUG = debug\n#******Environment Setup Ends******\nglobal response\nresponse=''\n#***********Grammar******************\ndef p_create_model(p):",
        "detail": "server.backend_app.mlsql.parser.parser",
        "documentation": {}
    },
    {
        "label": "DEBUG",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.parser",
        "description": "server.backend_app.mlsql.parser.parser",
        "peekOfCode": "DEBUG = True\ndef setDebug(debug = False):\n    global DEBUG\n    DEBUG = debug\n#******Environment Setup Ends******\nglobal response\nresponse=''\n#***********Grammar******************\ndef p_create_model(p):\n    '''exp : CREATE ESTIMATOR WORD MODEL_TYPE WORD FORMULA FORMULA_EXP DELIMITER",
        "detail": "server.backend_app.mlsql.parser.parser",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.parser",
        "description": "server.backend_app.mlsql.parser.parser",
        "peekOfCode": "parser = yacc.yacc(debug=True)\n# with open(\"parser/parser.dill\", \"wb\") as f:\n#     dill.dump(parser, f)\n# def welcome():\n#     print(f'''\n# ******** Welcome to MLSQL (version egg)*******\n# The first open-source SQL for Machine Learning\n# **********************************************\n# ''')\n#     pass",
        "detail": "server.backend_app.mlsql.parser.parser",
        "documentation": {}
    },
    {
        "label": "_tabversion",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.parsetab",
        "description": "server.backend_app.mlsql.parser.parsetab",
        "peekOfCode": "_tabversion = '3.10'\n_lr_method = 'LALR'\n_lr_signature = 'AND AS BATCH_SIZE BOOL BY CLONE CREATE DEBUG DELIMITER EPOCH ESTIMATOR FLOAT FORMULA FORMULA_EXP INT LEARNING_RATE LOSS LPAREN MODEL MODEL_TYPE OPTIMIZER PREDICT REGULARIZER RPAREN SET SHUFFLE SQL TABLE TEST TRAIN TRAINING_PROFILE URL USE VALIDATION_SPLIT WEIGHTS WITH WORDexp : CREATE ESTIMATOR WORD MODEL_TYPE WORD FORMULA FORMULA_EXP DELIMITER\\n            | CREATE ESTIMATOR WORD MODEL_TYPE WORD FORMULA FORMULA_EXP LOSS WORD DELIMITER\\n            | CREATE ESTIMATOR WORD MODEL_TYPE WORD FORMULA FORMULA_EXP LOSS WORD LEARNING_RATE FLOAT DELIMITER\\n            | CREATE ESTIMATOR WORD MODEL_TYPE WORD FORMULA FORMULA_EXP LOSS WORD LEARNING_RATE FLOAT OPTIMIZER WORD REGULARIZER WORD DELIMITERexp : CREATE TRAINING_PROFILE WORD WITH SQL DELIMITER\\n                | CREATE TRAINING_PROFILE WORD WITH SQL AND VALIDATION_SPLIT FLOAT DELIMITER\\n                | CREATE TRAINING_PROFILE WORD WITH SQL AND VALIDATION_SPLIT FLOAT BATCH_SIZE INT EPOCH INT DELIMITER\\n                | CREATE TRAINING_PROFILE WORD WITH SQL AND VALIDATION_SPLIT FLOAT BATCH_SIZE INT EPOCH INT SHUFFLE BOOL DELIMITERexp : TRAIN WORD WITH WORD DELIMITER\\n           | TRAIN WORD WITH TRAINING_PROFILE WORD DELIMITERexp : PREDICT WITH SQL BY ESTIMATOR WORD DELIMITER\\n           | PREDICT WITH TRAINING_PROFILE WORD BY ESTIMATOR WORD DELIMITERexp : CLONE ESTIMATOR WORD AS WORD DELIMITER\\n           | CLONE ESTIMATOR WORD AS WORD WITH WEIGHTS DELIMITERexp : USE URL DELIMITERexp : SQL DELIMITERexp : SET DEBUG BOOL DELIMITER'\n_lr_action_items = {'CREATE':([0,],[2,]),'TRAIN':([0,],[4,]),'PREDICT':([0,],[5,]),'CLONE':([0,],[6,]),'USE':([0,],[7,]),'SQL':([0,13,26,],[3,20,34,]),'SET':([0,],[8,]),'$end':([1,11,23,32,35,41,43,46,50,53,56,57,59,61,66,70,75,76,],[0,-16,-15,-17,-9,-5,-10,-13,-11,-1,-12,-14,-6,-2,-3,-7,-8,-4,]),'ESTIMATOR':([2,6,29,38,],[9,14,37,45,]),'TRAINING_PROFILE':([2,13,19,],[10,21,28,]),'DELIMITER':([3,15,24,27,34,36,39,44,48,51,52,55,58,64,68,73,74,],[11,23,32,35,41,43,46,50,53,56,57,59,61,66,70,75,76,]),'WORD':([4,9,10,14,19,21,25,28,31,37,45,54,67,72,],[12,17,18,22,27,30,33,36,39,44,51,58,69,74,]),'WITH':([5,12,18,39,],[13,19,26,47,]),'URL':([7,],[15,]),'DEBUG':([8,],[16,]),'BOOL':([16,71,],[24,73,]),'MODEL_TYPE':([17,],[25,]),'BY':([20,30,],[29,38,]),'AS':([22,],[31,]),'FORMULA':([33,],[40,]),'AND':([34,],[42,]),'FORMULA_EXP':([40,],[48,]),'VALIDATION_SPLIT':([42,],[49,]),'WEIGHTS':([47,],[52,]),'LOSS':([48,],[54,]),'FLOAT':([49,62,],[55,64,]),'BATCH_SIZE':([55,],[60,]),'LEARNING_RATE':([58,],[62,]),'INT':([60,65,],[63,68,]),'EPOCH':([63,],[65,]),'OPTIMIZER':([64,],[67,]),'SHUFFLE':([68,],[71,]),'REGULARIZER':([69,],[72,]),}\n_lr_action = {}\nfor _k, _v in _lr_action_items.items():\n   for _x,_y in zip(_v[0],_v[1]):\n      if not _x in _lr_action:  _lr_action[_x] = {}\n      _lr_action[_x][_k] = _y\ndel _lr_action_items",
        "detail": "server.backend_app.mlsql.parser.parsetab",
        "documentation": {}
    },
    {
        "label": "_lr_method",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.parsetab",
        "description": "server.backend_app.mlsql.parser.parsetab",
        "peekOfCode": "_lr_method = 'LALR'\n_lr_signature = 'AND AS BATCH_SIZE BOOL BY CLONE CREATE DEBUG DELIMITER EPOCH ESTIMATOR FLOAT FORMULA FORMULA_EXP INT LEARNING_RATE LOSS LPAREN MODEL MODEL_TYPE OPTIMIZER PREDICT REGULARIZER RPAREN SET SHUFFLE SQL TABLE TEST TRAIN TRAINING_PROFILE URL USE VALIDATION_SPLIT WEIGHTS WITH WORDexp : CREATE ESTIMATOR WORD MODEL_TYPE WORD FORMULA FORMULA_EXP DELIMITER\\n            | CREATE ESTIMATOR WORD MODEL_TYPE WORD FORMULA FORMULA_EXP LOSS WORD DELIMITER\\n            | CREATE ESTIMATOR WORD MODEL_TYPE WORD FORMULA FORMULA_EXP LOSS WORD LEARNING_RATE FLOAT DELIMITER\\n            | CREATE ESTIMATOR WORD MODEL_TYPE WORD FORMULA FORMULA_EXP LOSS WORD LEARNING_RATE FLOAT OPTIMIZER WORD REGULARIZER WORD DELIMITERexp : CREATE TRAINING_PROFILE WORD WITH SQL DELIMITER\\n                | CREATE TRAINING_PROFILE WORD WITH SQL AND VALIDATION_SPLIT FLOAT DELIMITER\\n                | CREATE TRAINING_PROFILE WORD WITH SQL AND VALIDATION_SPLIT FLOAT BATCH_SIZE INT EPOCH INT DELIMITER\\n                | CREATE TRAINING_PROFILE WORD WITH SQL AND VALIDATION_SPLIT FLOAT BATCH_SIZE INT EPOCH INT SHUFFLE BOOL DELIMITERexp : TRAIN WORD WITH WORD DELIMITER\\n           | TRAIN WORD WITH TRAINING_PROFILE WORD DELIMITERexp : PREDICT WITH SQL BY ESTIMATOR WORD DELIMITER\\n           | PREDICT WITH TRAINING_PROFILE WORD BY ESTIMATOR WORD DELIMITERexp : CLONE ESTIMATOR WORD AS WORD DELIMITER\\n           | CLONE ESTIMATOR WORD AS WORD WITH WEIGHTS DELIMITERexp : USE URL DELIMITERexp : SQL DELIMITERexp : SET DEBUG BOOL DELIMITER'\n_lr_action_items = {'CREATE':([0,],[2,]),'TRAIN':([0,],[4,]),'PREDICT':([0,],[5,]),'CLONE':([0,],[6,]),'USE':([0,],[7,]),'SQL':([0,13,26,],[3,20,34,]),'SET':([0,],[8,]),'$end':([1,11,23,32,35,41,43,46,50,53,56,57,59,61,66,70,75,76,],[0,-16,-15,-17,-9,-5,-10,-13,-11,-1,-12,-14,-6,-2,-3,-7,-8,-4,]),'ESTIMATOR':([2,6,29,38,],[9,14,37,45,]),'TRAINING_PROFILE':([2,13,19,],[10,21,28,]),'DELIMITER':([3,15,24,27,34,36,39,44,48,51,52,55,58,64,68,73,74,],[11,23,32,35,41,43,46,50,53,56,57,59,61,66,70,75,76,]),'WORD':([4,9,10,14,19,21,25,28,31,37,45,54,67,72,],[12,17,18,22,27,30,33,36,39,44,51,58,69,74,]),'WITH':([5,12,18,39,],[13,19,26,47,]),'URL':([7,],[15,]),'DEBUG':([8,],[16,]),'BOOL':([16,71,],[24,73,]),'MODEL_TYPE':([17,],[25,]),'BY':([20,30,],[29,38,]),'AS':([22,],[31,]),'FORMULA':([33,],[40,]),'AND':([34,],[42,]),'FORMULA_EXP':([40,],[48,]),'VALIDATION_SPLIT':([42,],[49,]),'WEIGHTS':([47,],[52,]),'LOSS':([48,],[54,]),'FLOAT':([49,62,],[55,64,]),'BATCH_SIZE':([55,],[60,]),'LEARNING_RATE':([58,],[62,]),'INT':([60,65,],[63,68,]),'EPOCH':([63,],[65,]),'OPTIMIZER':([64,],[67,]),'SHUFFLE':([68,],[71,]),'REGULARIZER':([69,],[72,]),}\n_lr_action = {}\nfor _k, _v in _lr_action_items.items():\n   for _x,_y in zip(_v[0],_v[1]):\n      if not _x in _lr_action:  _lr_action[_x] = {}\n      _lr_action[_x][_k] = _y\ndel _lr_action_items\n_lr_goto_items = {'exp':([0,],[1,]),}",
        "detail": "server.backend_app.mlsql.parser.parsetab",
        "documentation": {}
    },
    {
        "label": "_lr_signature",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.parsetab",
        "description": "server.backend_app.mlsql.parser.parsetab",
        "peekOfCode": "_lr_signature = 'AND AS BATCH_SIZE BOOL BY CLONE CREATE DEBUG DELIMITER EPOCH ESTIMATOR FLOAT FORMULA FORMULA_EXP INT LEARNING_RATE LOSS LPAREN MODEL MODEL_TYPE OPTIMIZER PREDICT REGULARIZER RPAREN SET SHUFFLE SQL TABLE TEST TRAIN TRAINING_PROFILE URL USE VALIDATION_SPLIT WEIGHTS WITH WORDexp : CREATE ESTIMATOR WORD MODEL_TYPE WORD FORMULA FORMULA_EXP DELIMITER\\n            | CREATE ESTIMATOR WORD MODEL_TYPE WORD FORMULA FORMULA_EXP LOSS WORD DELIMITER\\n            | CREATE ESTIMATOR WORD MODEL_TYPE WORD FORMULA FORMULA_EXP LOSS WORD LEARNING_RATE FLOAT DELIMITER\\n            | CREATE ESTIMATOR WORD MODEL_TYPE WORD FORMULA FORMULA_EXP LOSS WORD LEARNING_RATE FLOAT OPTIMIZER WORD REGULARIZER WORD DELIMITERexp : CREATE TRAINING_PROFILE WORD WITH SQL DELIMITER\\n                | CREATE TRAINING_PROFILE WORD WITH SQL AND VALIDATION_SPLIT FLOAT DELIMITER\\n                | CREATE TRAINING_PROFILE WORD WITH SQL AND VALIDATION_SPLIT FLOAT BATCH_SIZE INT EPOCH INT DELIMITER\\n                | CREATE TRAINING_PROFILE WORD WITH SQL AND VALIDATION_SPLIT FLOAT BATCH_SIZE INT EPOCH INT SHUFFLE BOOL DELIMITERexp : TRAIN WORD WITH WORD DELIMITER\\n           | TRAIN WORD WITH TRAINING_PROFILE WORD DELIMITERexp : PREDICT WITH SQL BY ESTIMATOR WORD DELIMITER\\n           | PREDICT WITH TRAINING_PROFILE WORD BY ESTIMATOR WORD DELIMITERexp : CLONE ESTIMATOR WORD AS WORD DELIMITER\\n           | CLONE ESTIMATOR WORD AS WORD WITH WEIGHTS DELIMITERexp : USE URL DELIMITERexp : SQL DELIMITERexp : SET DEBUG BOOL DELIMITER'\n_lr_action_items = {'CREATE':([0,],[2,]),'TRAIN':([0,],[4,]),'PREDICT':([0,],[5,]),'CLONE':([0,],[6,]),'USE':([0,],[7,]),'SQL':([0,13,26,],[3,20,34,]),'SET':([0,],[8,]),'$end':([1,11,23,32,35,41,43,46,50,53,56,57,59,61,66,70,75,76,],[0,-16,-15,-17,-9,-5,-10,-13,-11,-1,-12,-14,-6,-2,-3,-7,-8,-4,]),'ESTIMATOR':([2,6,29,38,],[9,14,37,45,]),'TRAINING_PROFILE':([2,13,19,],[10,21,28,]),'DELIMITER':([3,15,24,27,34,36,39,44,48,51,52,55,58,64,68,73,74,],[11,23,32,35,41,43,46,50,53,56,57,59,61,66,70,75,76,]),'WORD':([4,9,10,14,19,21,25,28,31,37,45,54,67,72,],[12,17,18,22,27,30,33,36,39,44,51,58,69,74,]),'WITH':([5,12,18,39,],[13,19,26,47,]),'URL':([7,],[15,]),'DEBUG':([8,],[16,]),'BOOL':([16,71,],[24,73,]),'MODEL_TYPE':([17,],[25,]),'BY':([20,30,],[29,38,]),'AS':([22,],[31,]),'FORMULA':([33,],[40,]),'AND':([34,],[42,]),'FORMULA_EXP':([40,],[48,]),'VALIDATION_SPLIT':([42,],[49,]),'WEIGHTS':([47,],[52,]),'LOSS':([48,],[54,]),'FLOAT':([49,62,],[55,64,]),'BATCH_SIZE':([55,],[60,]),'LEARNING_RATE':([58,],[62,]),'INT':([60,65,],[63,68,]),'EPOCH':([63,],[65,]),'OPTIMIZER':([64,],[67,]),'SHUFFLE':([68,],[71,]),'REGULARIZER':([69,],[72,]),}\n_lr_action = {}\nfor _k, _v in _lr_action_items.items():\n   for _x,_y in zip(_v[0],_v[1]):\n      if not _x in _lr_action:  _lr_action[_x] = {}\n      _lr_action[_x][_k] = _y\ndel _lr_action_items\n_lr_goto_items = {'exp':([0,],[1,]),}\n_lr_goto = {}",
        "detail": "server.backend_app.mlsql.parser.parsetab",
        "documentation": {}
    },
    {
        "label": "_lr_action_items",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.parsetab",
        "description": "server.backend_app.mlsql.parser.parsetab",
        "peekOfCode": "_lr_action_items = {'CREATE':([0,],[2,]),'TRAIN':([0,],[4,]),'PREDICT':([0,],[5,]),'CLONE':([0,],[6,]),'USE':([0,],[7,]),'SQL':([0,13,26,],[3,20,34,]),'SET':([0,],[8,]),'$end':([1,11,23,32,35,41,43,46,50,53,56,57,59,61,66,70,75,76,],[0,-16,-15,-17,-9,-5,-10,-13,-11,-1,-12,-14,-6,-2,-3,-7,-8,-4,]),'ESTIMATOR':([2,6,29,38,],[9,14,37,45,]),'TRAINING_PROFILE':([2,13,19,],[10,21,28,]),'DELIMITER':([3,15,24,27,34,36,39,44,48,51,52,55,58,64,68,73,74,],[11,23,32,35,41,43,46,50,53,56,57,59,61,66,70,75,76,]),'WORD':([4,9,10,14,19,21,25,28,31,37,45,54,67,72,],[12,17,18,22,27,30,33,36,39,44,51,58,69,74,]),'WITH':([5,12,18,39,],[13,19,26,47,]),'URL':([7,],[15,]),'DEBUG':([8,],[16,]),'BOOL':([16,71,],[24,73,]),'MODEL_TYPE':([17,],[25,]),'BY':([20,30,],[29,38,]),'AS':([22,],[31,]),'FORMULA':([33,],[40,]),'AND':([34,],[42,]),'FORMULA_EXP':([40,],[48,]),'VALIDATION_SPLIT':([42,],[49,]),'WEIGHTS':([47,],[52,]),'LOSS':([48,],[54,]),'FLOAT':([49,62,],[55,64,]),'BATCH_SIZE':([55,],[60,]),'LEARNING_RATE':([58,],[62,]),'INT':([60,65,],[63,68,]),'EPOCH':([63,],[65,]),'OPTIMIZER':([64,],[67,]),'SHUFFLE':([68,],[71,]),'REGULARIZER':([69,],[72,]),}\n_lr_action = {}\nfor _k, _v in _lr_action_items.items():\n   for _x,_y in zip(_v[0],_v[1]):\n      if not _x in _lr_action:  _lr_action[_x] = {}\n      _lr_action[_x][_k] = _y\ndel _lr_action_items\n_lr_goto_items = {'exp':([0,],[1,]),}\n_lr_goto = {}\nfor _k, _v in _lr_goto_items.items():",
        "detail": "server.backend_app.mlsql.parser.parsetab",
        "documentation": {}
    },
    {
        "label": "_lr_action",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.parsetab",
        "description": "server.backend_app.mlsql.parser.parsetab",
        "peekOfCode": "_lr_action = {}\nfor _k, _v in _lr_action_items.items():\n   for _x,_y in zip(_v[0],_v[1]):\n      if not _x in _lr_action:  _lr_action[_x] = {}\n      _lr_action[_x][_k] = _y\ndel _lr_action_items\n_lr_goto_items = {'exp':([0,],[1,]),}\n_lr_goto = {}\nfor _k, _v in _lr_goto_items.items():\n   for _x, _y in zip(_v[0], _v[1]):",
        "detail": "server.backend_app.mlsql.parser.parsetab",
        "documentation": {}
    },
    {
        "label": "_lr_goto_items",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.parsetab",
        "description": "server.backend_app.mlsql.parser.parsetab",
        "peekOfCode": "_lr_goto_items = {'exp':([0,],[1,]),}\n_lr_goto = {}\nfor _k, _v in _lr_goto_items.items():\n   for _x, _y in zip(_v[0], _v[1]):\n       if not _x in _lr_goto: _lr_goto[_x] = {}\n       _lr_goto[_x][_k] = _y\ndel _lr_goto_items\n_lr_productions = [\n  (\"S' -> exp\",\"S'\",1,None,None,None),\n  ('exp -> CREATE ESTIMATOR WORD MODEL_TYPE WORD FORMULA FORMULA_EXP DELIMITER','exp',8,'p_create_model','parser.py',49),",
        "detail": "server.backend_app.mlsql.parser.parsetab",
        "documentation": {}
    },
    {
        "label": "_lr_goto",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.parsetab",
        "description": "server.backend_app.mlsql.parser.parsetab",
        "peekOfCode": "_lr_goto = {}\nfor _k, _v in _lr_goto_items.items():\n   for _x, _y in zip(_v[0], _v[1]):\n       if not _x in _lr_goto: _lr_goto[_x] = {}\n       _lr_goto[_x][_k] = _y\ndel _lr_goto_items\n_lr_productions = [\n  (\"S' -> exp\",\"S'\",1,None,None,None),\n  ('exp -> CREATE ESTIMATOR WORD MODEL_TYPE WORD FORMULA FORMULA_EXP DELIMITER','exp',8,'p_create_model','parser.py',49),\n  ('exp -> CREATE ESTIMATOR WORD MODEL_TYPE WORD FORMULA FORMULA_EXP LOSS WORD DELIMITER','exp',10,'p_create_model','parser.py',50),",
        "detail": "server.backend_app.mlsql.parser.parsetab",
        "documentation": {}
    },
    {
        "label": "_lr_productions",
        "kind": 5,
        "importPath": "server.backend_app.mlsql.parser.parsetab",
        "description": "server.backend_app.mlsql.parser.parsetab",
        "peekOfCode": "_lr_productions = [\n  (\"S' -> exp\",\"S'\",1,None,None,None),\n  ('exp -> CREATE ESTIMATOR WORD MODEL_TYPE WORD FORMULA FORMULA_EXP DELIMITER','exp',8,'p_create_model','parser.py',49),\n  ('exp -> CREATE ESTIMATOR WORD MODEL_TYPE WORD FORMULA FORMULA_EXP LOSS WORD DELIMITER','exp',10,'p_create_model','parser.py',50),\n  ('exp -> CREATE ESTIMATOR WORD MODEL_TYPE WORD FORMULA FORMULA_EXP LOSS WORD LEARNING_RATE FLOAT DELIMITER','exp',12,'p_create_model','parser.py',51),\n  ('exp -> CREATE ESTIMATOR WORD MODEL_TYPE WORD FORMULA FORMULA_EXP LOSS WORD LEARNING_RATE FLOAT OPTIMIZER WORD REGULARIZER WORD DELIMITER','exp',16,'p_create_model','parser.py',52),\n  ('exp -> CREATE TRAINING_PROFILE WORD WITH SQL DELIMITER','exp',6,'p_training_profile','parser.py',103),\n  ('exp -> CREATE TRAINING_PROFILE WORD WITH SQL AND VALIDATION_SPLIT FLOAT DELIMITER','exp',9,'p_training_profile','parser.py',104),\n  ('exp -> CREATE TRAINING_PROFILE WORD WITH SQL AND VALIDATION_SPLIT FLOAT BATCH_SIZE INT EPOCH INT DELIMITER','exp',13,'p_training_profile','parser.py',105),\n  ('exp -> CREATE TRAINING_PROFILE WORD WITH SQL AND VALIDATION_SPLIT FLOAT BATCH_SIZE INT EPOCH INT SHUFFLE BOOL DELIMITER','exp',15,'p_training_profile','parser.py',106),",
        "detail": "server.backend_app.mlsql.parser.parsetab",
        "documentation": {}
    },
    {
        "label": "query_process",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.parser.query_process",
        "description": "server.backend_app.mlsql.parser.query_process",
        "peekOfCode": "def query_process(data):\n    global type_name, model_table_name, target_var, other_ftr, response,currentDB\n    if data.upper().startswith(\"USE\"):\n        splitted_data = data.split()\n        currentDB = splitted_data[1].split(';')[0]\n        response = _parser(f\"USE 'data/{currentDB}.db';\")\n        yield response\n    elif data.upper().startswith(\"CONSTRUCT\"):\n        '''CONSTRUCT PREDICTION MonthlySales ALGORITHM GB WITH  LABEL ProductID FEATURES Age Price StockLevel FROM retail OVER retailTestData ;\n           CONSTRUCT CLASSIFICATION Species ALGORITHM KNN WITH  LABEL ProductID FEATURES SepalLengthCm SepalWidthCm FROM Iris ;",
        "detail": "server.backend_app.mlsql.parser.query_process",
        "documentation": {}
    },
    {
        "label": "csvToDB",
        "kind": 2,
        "importPath": "server.backend_app.mlsql.test.csvToDB",
        "description": "server.backend_app.mlsql.test.csvToDB",
        "peekOfCode": "def csvToDB(csv_file):\n    df = pd.read_csv(csv_file)\n    file_name,_=os.path.splitext(csv_file.name)\n    current_directory = os.path.dirname(__file__)\n    file_location=os.path.join(current_directory,f'../data/files/{file_name}.db')\n    conn = sqlite3.connect(file_location)\n    df.to_sql(file_name, conn, index=False, if_exists='replace')\n    conn.commit()\n    conn.close()\n    print(\"CSV dataset successfully converted to SQLite database.\")",
        "detail": "server.backend_app.mlsql.test.csvToDB",
        "documentation": {}
    },
    {
        "label": "test_view",
        "kind": 2,
        "importPath": "server.backend_app.views",
        "description": "server.backend_app.views",
        "peekOfCode": "def test_view(req):\n    if req.method == 'POST':\n        current_directory = os.path.dirname(__file__)\n        if 'file' in req.FILES:\n            file = req.FILES['file']\n            file_name = file.name\n            file_path = os.path.join(current_directory, f'./mlsql/data/files/{file_name}')\n            if file_name.endswith('.csv'):\n                csvToDB(file)\n            else:",
        "detail": "server.backend_app.views",
        "documentation": {}
    },
    {
        "label": "application",
        "kind": 5,
        "importPath": "server.dl4ml.asgi",
        "description": "server.dl4ml.asgi",
        "peekOfCode": "application = get_asgi_application()",
        "detail": "server.dl4ml.asgi",
        "documentation": {}
    },
    {
        "label": "BASE_DIR",
        "kind": 5,
        "importPath": "server.dl4ml.settings",
        "description": "server.dl4ml.settings",
        "peekOfCode": "BASE_DIR = Path(__file__).resolve().parent.parent\n# Quick-start development settings - unsuitable for production\n# See https://docs.djangoproject.com/en/5.0/howto/deployment/checklist/\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = 'django-insecure-j1zm0jk%a)=9u2r(n6q%&ey2zp$xt5^0txs=ws!iew=p-%d(=='\n# SECURITY WARNING: don't run with debug turned on in production!\nDEBUG = True\nALLOWED_HOSTS = []\n# Application definition\nINSTALLED_APPS = [",
        "detail": "server.dl4ml.settings",
        "documentation": {}
    },
    {
        "label": "SECRET_KEY",
        "kind": 5,
        "importPath": "server.dl4ml.settings",
        "description": "server.dl4ml.settings",
        "peekOfCode": "SECRET_KEY = 'django-insecure-j1zm0jk%a)=9u2r(n6q%&ey2zp$xt5^0txs=ws!iew=p-%d(=='\n# SECURITY WARNING: don't run with debug turned on in production!\nDEBUG = True\nALLOWED_HOSTS = []\n# Application definition\nINSTALLED_APPS = [\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',",
        "detail": "server.dl4ml.settings",
        "documentation": {}
    },
    {
        "label": "DEBUG",
        "kind": 5,
        "importPath": "server.dl4ml.settings",
        "description": "server.dl4ml.settings",
        "peekOfCode": "DEBUG = True\nALLOWED_HOSTS = []\n# Application definition\nINSTALLED_APPS = [\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',",
        "detail": "server.dl4ml.settings",
        "documentation": {}
    },
    {
        "label": "ALLOWED_HOSTS",
        "kind": 5,
        "importPath": "server.dl4ml.settings",
        "description": "server.dl4ml.settings",
        "peekOfCode": "ALLOWED_HOSTS = []\n# Application definition\nINSTALLED_APPS = [\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n    'backend_app',",
        "detail": "server.dl4ml.settings",
        "documentation": {}
    },
    {
        "label": "INSTALLED_APPS",
        "kind": 5,
        "importPath": "server.dl4ml.settings",
        "description": "server.dl4ml.settings",
        "peekOfCode": "INSTALLED_APPS = [\n    'django.contrib.admin',\n    'django.contrib.auth',\n    'django.contrib.contenttypes',\n    'django.contrib.sessions',\n    'django.contrib.messages',\n    'django.contrib.staticfiles',\n    'backend_app',\n    'corsheaders',\n]",
        "detail": "server.dl4ml.settings",
        "documentation": {}
    },
    {
        "label": "MIDDLEWARE",
        "kind": 5,
        "importPath": "server.dl4ml.settings",
        "description": "server.dl4ml.settings",
        "peekOfCode": "MIDDLEWARE = [\n    'django.middleware.security.SecurityMiddleware',\n    'django.contrib.sessions.middleware.SessionMiddleware',\n    'django.middleware.common.CommonMiddleware',\n    'django.middleware.csrf.CsrfViewMiddleware',\n    'django.contrib.auth.middleware.AuthenticationMiddleware',\n    'django.contrib.messages.middleware.MessageMiddleware',\n    'django.middleware.clickjacking.XFrameOptionsMiddleware',\n    'corsheaders.middleware.CorsMiddleware',\n    'django.middleware.common.CommonMiddleware',",
        "detail": "server.dl4ml.settings",
        "documentation": {}
    },
    {
        "label": "CORS_ALLOWED_ORIGINS",
        "kind": 5,
        "importPath": "server.dl4ml.settings",
        "description": "server.dl4ml.settings",
        "peekOfCode": "CORS_ALLOWED_ORIGINS = [\n    'http://localhost:5173',\n]\nROOT_URLCONF = 'dl4ml.urls'\nTEMPLATES = [\n    {\n        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n        'DIRS': [os.path.join(BASE_DIR, 'templates')],\n        'APP_DIRS': True,\n        'OPTIONS': {",
        "detail": "server.dl4ml.settings",
        "documentation": {}
    },
    {
        "label": "ROOT_URLCONF",
        "kind": 5,
        "importPath": "server.dl4ml.settings",
        "description": "server.dl4ml.settings",
        "peekOfCode": "ROOT_URLCONF = 'dl4ml.urls'\nTEMPLATES = [\n    {\n        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n        'DIRS': [os.path.join(BASE_DIR, 'templates')],\n        'APP_DIRS': True,\n        'OPTIONS': {\n            'context_processors': [\n                'django.template.context_processors.debug',\n                'django.template.context_processors.request',",
        "detail": "server.dl4ml.settings",
        "documentation": {}
    },
    {
        "label": "TEMPLATES",
        "kind": 5,
        "importPath": "server.dl4ml.settings",
        "description": "server.dl4ml.settings",
        "peekOfCode": "TEMPLATES = [\n    {\n        'BACKEND': 'django.template.backends.django.DjangoTemplates',\n        'DIRS': [os.path.join(BASE_DIR, 'templates')],\n        'APP_DIRS': True,\n        'OPTIONS': {\n            'context_processors': [\n                'django.template.context_processors.debug',\n                'django.template.context_processors.request',\n                'django.contrib.auth.context_processors.auth',",
        "detail": "server.dl4ml.settings",
        "documentation": {}
    },
    {
        "label": "WSGI_APPLICATION",
        "kind": 5,
        "importPath": "server.dl4ml.settings",
        "description": "server.dl4ml.settings",
        "peekOfCode": "WSGI_APPLICATION = 'dl4ml.wsgi.application'\n# Database\n# https://docs.djangoproject.com/en/5.0/ref/settings/#databases\nDATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.sqlite3',\n        'NAME': BASE_DIR / 'db.sqlite3',\n    }\n}\n# Password validation",
        "detail": "server.dl4ml.settings",
        "documentation": {}
    },
    {
        "label": "DATABASES",
        "kind": 5,
        "importPath": "server.dl4ml.settings",
        "description": "server.dl4ml.settings",
        "peekOfCode": "DATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.sqlite3',\n        'NAME': BASE_DIR / 'db.sqlite3',\n    }\n}\n# Password validation\n# https://docs.djangoproject.com/en/5.0/ref/settings/#auth-password-validators\nAUTH_PASSWORD_VALIDATORS = [\n    {",
        "detail": "server.dl4ml.settings",
        "documentation": {}
    },
    {
        "label": "AUTH_PASSWORD_VALIDATORS",
        "kind": 5,
        "importPath": "server.dl4ml.settings",
        "description": "server.dl4ml.settings",
        "peekOfCode": "AUTH_PASSWORD_VALIDATORS = [\n    {\n        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',\n    },\n    {\n        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',\n    },\n    {\n        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',\n    },",
        "detail": "server.dl4ml.settings",
        "documentation": {}
    },
    {
        "label": "LANGUAGE_CODE",
        "kind": 5,
        "importPath": "server.dl4ml.settings",
        "description": "server.dl4ml.settings",
        "peekOfCode": "LANGUAGE_CODE = 'en-us'\nTIME_ZONE = 'UTC'\nUSE_I18N = True\nUSE_TZ = True\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/5.0/howto/static-files/\nSTATIC_URL = 'static/'\n# Default primary key field type\n# https://docs.djangoproject.com/en/5.0/ref/settings/#default-auto-field\nFILE_UPLOAD_HANDLERS = [",
        "detail": "server.dl4ml.settings",
        "documentation": {}
    },
    {
        "label": "TIME_ZONE",
        "kind": 5,
        "importPath": "server.dl4ml.settings",
        "description": "server.dl4ml.settings",
        "peekOfCode": "TIME_ZONE = 'UTC'\nUSE_I18N = True\nUSE_TZ = True\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/5.0/howto/static-files/\nSTATIC_URL = 'static/'\n# Default primary key field type\n# https://docs.djangoproject.com/en/5.0/ref/settings/#default-auto-field\nFILE_UPLOAD_HANDLERS = [\n    'django.core.files.uploadhandler.MemoryFileUploadHandler',  # Handle file uploads in memory",
        "detail": "server.dl4ml.settings",
        "documentation": {}
    },
    {
        "label": "USE_I18N",
        "kind": 5,
        "importPath": "server.dl4ml.settings",
        "description": "server.dl4ml.settings",
        "peekOfCode": "USE_I18N = True\nUSE_TZ = True\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/5.0/howto/static-files/\nSTATIC_URL = 'static/'\n# Default primary key field type\n# https://docs.djangoproject.com/en/5.0/ref/settings/#default-auto-field\nFILE_UPLOAD_HANDLERS = [\n    'django.core.files.uploadhandler.MemoryFileUploadHandler',  # Handle file uploads in memory\n    'django.core.files.uploadhandler.TemporaryFileUploadHandler',  # Handle file uploads using temporary files",
        "detail": "server.dl4ml.settings",
        "documentation": {}
    },
    {
        "label": "USE_TZ",
        "kind": 5,
        "importPath": "server.dl4ml.settings",
        "description": "server.dl4ml.settings",
        "peekOfCode": "USE_TZ = True\n# Static files (CSS, JavaScript, Images)\n# https://docs.djangoproject.com/en/5.0/howto/static-files/\nSTATIC_URL = 'static/'\n# Default primary key field type\n# https://docs.djangoproject.com/en/5.0/ref/settings/#default-auto-field\nFILE_UPLOAD_HANDLERS = [\n    'django.core.files.uploadhandler.MemoryFileUploadHandler',  # Handle file uploads in memory\n    'django.core.files.uploadhandler.TemporaryFileUploadHandler',  # Handle file uploads using temporary files\n]",
        "detail": "server.dl4ml.settings",
        "documentation": {}
    },
    {
        "label": "STATIC_URL",
        "kind": 5,
        "importPath": "server.dl4ml.settings",
        "description": "server.dl4ml.settings",
        "peekOfCode": "STATIC_URL = 'static/'\n# Default primary key field type\n# https://docs.djangoproject.com/en/5.0/ref/settings/#default-auto-field\nFILE_UPLOAD_HANDLERS = [\n    'django.core.files.uploadhandler.MemoryFileUploadHandler',  # Handle file uploads in memory\n    'django.core.files.uploadhandler.TemporaryFileUploadHandler',  # Handle file uploads using temporary files\n]\nDEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'\nFILE_UPLOAD_MAX_MEMORY_SIZE = 90242880",
        "detail": "server.dl4ml.settings",
        "documentation": {}
    },
    {
        "label": "FILE_UPLOAD_HANDLERS",
        "kind": 5,
        "importPath": "server.dl4ml.settings",
        "description": "server.dl4ml.settings",
        "peekOfCode": "FILE_UPLOAD_HANDLERS = [\n    'django.core.files.uploadhandler.MemoryFileUploadHandler',  # Handle file uploads in memory\n    'django.core.files.uploadhandler.TemporaryFileUploadHandler',  # Handle file uploads using temporary files\n]\nDEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'\nFILE_UPLOAD_MAX_MEMORY_SIZE = 90242880",
        "detail": "server.dl4ml.settings",
        "documentation": {}
    },
    {
        "label": "DEFAULT_AUTO_FIELD",
        "kind": 5,
        "importPath": "server.dl4ml.settings",
        "description": "server.dl4ml.settings",
        "peekOfCode": "DEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'\nFILE_UPLOAD_MAX_MEMORY_SIZE = 90242880",
        "detail": "server.dl4ml.settings",
        "documentation": {}
    },
    {
        "label": "FILE_UPLOAD_MAX_MEMORY_SIZE",
        "kind": 5,
        "importPath": "server.dl4ml.settings",
        "description": "server.dl4ml.settings",
        "peekOfCode": "FILE_UPLOAD_MAX_MEMORY_SIZE = 90242880",
        "detail": "server.dl4ml.settings",
        "documentation": {}
    },
    {
        "label": "urlpatterns",
        "kind": 5,
        "importPath": "server.dl4ml.urls",
        "description": "server.dl4ml.urls",
        "peekOfCode": "urlpatterns = [\n    path('',lambda request: render(request, 'hi.html')),\n    # path('',hi),\n    path('admin/', admin.site.urls),\n    path('test_url/',test_view),\n    # path('upload_file/', upload)\n]",
        "detail": "server.dl4ml.urls",
        "documentation": {}
    },
    {
        "label": "application",
        "kind": 5,
        "importPath": "server.dl4ml.wsgi",
        "description": "server.dl4ml.wsgi",
        "peekOfCode": "application = get_wsgi_application()",
        "detail": "server.dl4ml.wsgi",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "server.manage",
        "description": "server.manage",
        "peekOfCode": "def main():\n    \"\"\"Run administrative tasks.\"\"\"\n    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'dl4ml.settings')\n    try:\n        from django.core.management import execute_from_command_line\n    except ImportError as exc:\n        raise ImportError(\n            \"Couldn't import Django. Are you sure it's installed and \"\n            \"available on your PYTHONPATH environment variable? Did you \"\n            \"forget to activate a virtual environment?\"",
        "detail": "server.manage",
        "documentation": {}
    }
]